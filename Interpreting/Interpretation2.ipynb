{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Interpretation2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPIc4kCPa/4RmCz9Dzv/znM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lustea0201/Interpretability/blob/master/Interpretation2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJWLB_GHkY_1",
        "colab_type": "text"
      },
      "source": [
        "# Interpreting the outputs of the model on the second dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wy5jZvelpXpl",
        "colab_type": "code",
        "outputId": "6b3032a7-713a-4bdb-b8d4-1f9444fbe150",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        }
      },
      "source": [
        "#@title\n",
        "import numpy as np\n",
        "import torch \n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import Resize, ToTensor, Normalize\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import zipfile\n",
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "!pip install flashtorch\n",
        "from flashtorch.saliency import Backprop\n",
        "\n",
        "!pip install shap \n",
        "import shap\n",
        "\n",
        "!pip install pytorch-gradcam\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid, save_image\n",
        "\n",
        "from gradcam.utils import visualize_cam\n",
        "from gradcam import GradCAM, GradCAMpp\n",
        "\n",
        "!wget https://raw.githubusercontent.com/yiskw713/SmoothGradCAMplusplus/master/cam.py -P local_modules -nc\n",
        "!wget https://raw.githubusercontent.com/yiskw713/SmoothGradCAMplusplus/master/utils/visualize.py -P local_modules -nc\n",
        "import sys\n",
        "sys.path.append('local_modules')\n",
        "from PIL import Image\n",
        "from local_modules.visualize import visualize\n",
        "import local_modules.cam as smooth\n",
        "\n",
        "!wget https://raw.githubusercontent.com/lustea0201/Interpretability/master/HierarchicalShapley.py -P local_modules -nc\n",
        "import local_modules.HierarchicalShapley as HS\n",
        "\n",
        "!wget https://raw.githubusercontent.com/lustea0201/Interpretability/master/utils.py -P local_modules -nc\n",
        "import local_modules.utils as utils\n",
        "\n",
        "!wget https://raw.githubusercontent.com/lustea0201/Interpretability/master/interpret11.py -P local_modules -nc\n",
        "import local_modules.interpret11 as intp\n",
        "\n",
        "torch.manual_seed(0)\n",
        "dtype = torch.float\n",
        "\n",
        "FIGSIZE = (5,4)\n",
        "\n",
        "net = utils.Net() # Model instantiation\n",
        "# Loading the trained dictionnary state\n",
        "net.load_state_dict(torch.load('drive/My Drive/Interpretability/model2.pth')) \n",
        "\n",
        "data = zipfile.ZipFile(\"/content/drive/My Drive/Interpretability/5000/data2/data.zip\", 'r')\n",
        "\n",
        "root_dir = \"main_dir\"\n",
        "data.extractall(root_dir)\n",
        "data.close()\n",
        "\n",
        "Batch_Size = 64\n",
        "#transf_temp =  transforms.Compose( [ToTensor()])\n",
        "#train_data_temp = ImageFolder(root = os.path.join(root_dir, 'train'), transform = transf_temp)\n",
        "#dataloader_temp = DataLoader(train_data_temp, batch_size = Batch_Size, shuffle = True, num_workers = 0)\n",
        "#MEAN, STD = utils.datasetMeanStd(dataloader_temp)\n",
        "MEAN, STD = np.array([0.5, 0.5, 0.5]), np.array([0.5, 0.5, 0.5])\n",
        "\n",
        "transf = transforms.Compose( [ToTensor(), Normalize(mean=MEAN, std=STD)])\n",
        "\n",
        "train_data = ImageFolder(root = os.path.join(root_dir, 'train'), transform = transf)\n",
        "dataloader = DataLoader(train_data, batch_size = Batch_Size, shuffle = True, num_workers = 0)\n",
        "train_loader = iter(dataloader)\n",
        "\n",
        "\n",
        "ImF = ImageFolder(root = \"/content/drive/My Drive/Interpretability/img4saliencymap/data2\", transform = transf)\n",
        "batch_Size = 3\n",
        "exloader = DataLoader(ImF, batch_size = batch_Size, shuffle = False, num_workers = 0)\n",
        "\n",
        "exIter = iter(exloader)\n",
        "images, labels = next(exIter)\n",
        "\n",
        "# For guided backprop\n",
        "backprop = Backprop(net)\n",
        "\n",
        "# For SHAP\n",
        "X,Y = next(train_loader)\n",
        "bg_choice = \"average\" # Default: entire training set, \"average\", \"white\", \"black\" \n",
        "# Median would result in white \n",
        "background = X\n",
        "if (bg_choice == \"black\"): \n",
        "  background = -torch.ones(X.shape)\n",
        "elif (bg_choice == \"white\"): \n",
        "  background = torch.ones(X.shape)\n",
        "elif (bg_choice == \"average\"): \n",
        "  avg = torch.mean(X, dim = 0)\n",
        "e = shap.GradientExplainer(net, background)\n",
        "\n",
        "# For GradCAM\n",
        "gradcam_conv = GradCAM(net, net.conv2)\n",
        "gradcam_pp_conv = GradCAMpp(net, net.conv2)\n",
        "gradcam_pool = GradCAM(net, net.pool2)\n",
        "gradcam_pp_pool = GradCAMpp(net, net.pool2)\n",
        "\n",
        "# For SmoothCAM\n",
        "target_layer = net.conv2\n",
        "wrapped_G = smooth.GradCAM(net, target_layer)\n",
        "wrapped_P = smooth.GradCAMpp(net, target_layer)\n",
        "wrapped_S = smooth.SmoothGradCAMpp(net, target_layer, n_samples=25, stdev_spread=0.15)\n",
        "wrapped = [wrapped_G, wrapped_P, wrapped_S]\n",
        "\n",
        "# For Hierarchical \n",
        "average = torch.mean(X, dim = 0)\n",
        "h = HS.HierarchicalShap(net, background = average)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'seaborn'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3e31cbe95ee6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yj-YQEPzpu37",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3be51f44-d0ce-40c2-c8d0-bf314e84992f"
      },
      "source": [
        "h.saliency_map(images[1], labels[1], tolerance = [2,3,4,5,6], only_one_run = False, max_depth = 30, debug = False)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'h' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-5fd6a71c556b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaliency_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monly_one_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'h' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6DZoWtfwTp6",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# EXAMPLE 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrXPeA60p9Xb",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "a1a8d515-7806-4449-e5d0-f8e632213fe8"
      },
      "source": [
        "image0 = images[0]\n",
        "label0 = labels[0]\n",
        "\n",
        "input0 = image0.view(-1, 3, 100, 120) # This shape is necessary for the network \n",
        "output0 = net(input0)\n",
        "_, predicted0 = torch.max(output0.data, 1)\n",
        "\n",
        "img0 = utils.input2image(image0, MEAN, STD)\n",
        "utils.display_image(img0, label0.numpy(), int(predicted0))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'images' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-d1dec0339a7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlabel0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minput0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m120\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# This shape is necessary for the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moutput0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34jSkq_pqmSy",
        "colab_type": "text"
      },
      "source": [
        "### Guided backpropagation explanation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvwjEy9Etipy",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "outputId": "b2895a14-5f13-4a04-df76-78094c93f3fc"
      },
      "source": [
        "input0.requires_grad = True # Necessary to compute the gradient\n",
        "gradients0 = backprop.calculate_gradients(input0, label0, guided = True).detach().numpy()\n",
        "intp.display_gradients(gradients0, FIGSIZE).suptitle(\"Guided backpropagation across the different channels for an image with label 0\", size=\"xx-large\");\n",
        "backprop.visualize(input0, label0, guided=True, figsize = (3*FIGSIZE[0], FIGSIZE[1]), cmap=\"bwr\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'input0' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-00e748dd850d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;31m# Necessary to compute the gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgradients0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguided\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mintp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFIGSIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuptitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Guided backpropagation across the different channels for an image with label 0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"xx-large\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguided\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mFIGSIZE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFIGSIZE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"bwr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'input0' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCH4yuMSdjCd",
        "colab_type": "text"
      },
      "source": [
        "### GradCAM explanation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L14e_TwWdjOD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4690566f-7db8-42bf-c4f9-082dde3a96af"
      },
      "source": [
        "intp.gradcam_exp(gradcam_conv, gradcam_pp_conv, input0, img0,  \"Second convolutional layer\", FIGSIZE)\n",
        "intp.gradcam_exp(gradcam_pool, gradcam_pp_pool, input0, img0,  \"Second pooling layer\", FIGSIZE)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'intp' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-9a5ec2d5c061>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mintp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradcam_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradcam_conv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradcam_pp_conv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg0\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m\"Second convolutional layer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFIGSIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mintp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradcam_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradcam_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradcam_pp_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg0\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m\"Second pooling layer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFIGSIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'intp' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6lDStxxdyxE",
        "colab_type": "text"
      },
      "source": [
        "### SmoothCAM explanation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivPV8F_xdyLF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "64554574-13ab-4b60-9c94-090ea8898b74"
      },
      "source": [
        "intp.smooth_exp(input0, image0, wrapped)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'intp' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-98fb9aa5348d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mintp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmooth_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'intp' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "525Zk4cvdaqz",
        "colab_type": "text"
      },
      "source": [
        "### Shapley explanation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOCXfrZLdKug",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f7b60ff4-2b68-4e91-df54-a4859d226529"
      },
      "source": [
        "intp.shap_exp(e, input0.detach(), img0)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'intp' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-092f4ffb74e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mintp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshap_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'intp' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWbPaiUrBc2T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "d44eb3e6-8433-434d-9f02-56b685ca40f3"
      },
      "source": [
        "e2 = shap.DeepExplainer(net, background)\n",
        "\n",
        "\n",
        "shap_values = e2.shap_values(input0.detach())\n",
        "shapley_values = [np.swapaxes(np.swapaxes(s, 2, 3), 1, -1) for s in shap_values]\n",
        "\n",
        "image00 = img0[np.newaxis, :]\n",
        "\n",
        "shap.image_plot(shapley_values, image00,  show=False)\n",
        "plt.suptitle(\"All channels together\");\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'shap' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-759c46325baa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0me2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDeepExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackground\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mshap_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mshapley_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshap_values\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'shap' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6epZU5m3eZ-s",
        "colab_type": "text"
      },
      "source": [
        "### Hierarchical Shapley explanation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gLgXcSUeaLw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8026e2d4-a00b-40c8-a50b-cd6ff8895974"
      },
      "source": [
        "h.saliency_map(image0, label0, tolerance  = [5,5.5,6,6.5,7])\n",
        "h.saliency_map(image0, label0, tolerance = [6], only_one_run = True)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'h' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-001d4e37c5af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaliency_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaliency_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monly_one_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'h' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a16oKk-gKl7O",
        "colab_type": "text"
      },
      "source": [
        "# EXAMPLE 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6ghRSmzeOok",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "6ca4063f-f870-4401-a2f5-2c0021c82ebb"
      },
      "source": [
        "image1 = images[1]\n",
        "label1 = labels[1]\n",
        "\n",
        "input1 = image1.view(-1, 3, 100, 120)\n",
        "output1 = net(input1)\n",
        "_, predicted1 = torch.max(output1.data, 1)\n",
        "\n",
        "img1 = utils.input2image(image1, MEAN, STD)\n",
        "utils.display_image(img1, label1.numpy(), int(predicted1))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'images' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-117790a5ab90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlabel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minput1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m120\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moutput1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0F2SksFyfNyo",
        "colab_type": "text"
      },
      "source": [
        "### Backpropagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZc1AkJCe7hJ",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "outputId": "1c5ce47e-7a66-46df-88ca-1b874c913547"
      },
      "source": [
        "input1.requires_grad = True # Necessary to compute the gradient\n",
        "gradients1 = backprop.calculate_gradients(input1, label1, guided = True).detach().numpy()\n",
        "intp.display_gradients(gradients1, FIGSIZE).suptitle(\"Guided backpropagation across the different channels for an image with label 0\", size=\"xx-large\");\n",
        "backprop.visualize(input1, label1, guided=True, figsize = (3*FIGSIZE[0], FIGSIZE[1]), cmap=\"bwr\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'input1' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-10f8820865df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;31m# Necessary to compute the gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgradients1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguided\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mintp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFIGSIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuptitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Guided backpropagation across the different channels for an image with label 0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"xx-large\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguided\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mFIGSIZE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFIGSIZE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"bwr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'input1' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYzNEkgPfTVe",
        "colab_type": "text"
      },
      "source": [
        "### GradCAM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3KonhoofTfn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "531b9dca-179f-4fa0-b1b6-6f63e93fd8e9"
      },
      "source": [
        "intp.gradcam_exp(gradcam_conv, gradcam_pp_conv, input1, img1,  \"Second convolutional layer\", FIGSIZE)\n",
        "intp.gradcam_exp(gradcam_pool, gradcam_pp_pool, input1, img1,  \"Second pooling layer\", FIGSIZE)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'intp' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-8e21279691e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mintp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradcam_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradcam_conv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradcam_pp_conv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg1\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m\"Second convolutional layer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFIGSIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mintp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradcam_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradcam_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradcam_pp_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg1\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m\"Second pooling layer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFIGSIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'intp' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UtIzMN0fs1e",
        "colab_type": "text"
      },
      "source": [
        "### SmoothCAM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6KJNxBCfs71",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f8958b8e-8471-47f8-b6ba-687043eed613"
      },
      "source": [
        "intp.smooth_exp(input1, image1, wrapped)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'intp' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-d5dd34ebd2ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mintp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmooth_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'intp' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjuiiMADfRvL",
        "colab_type": "text"
      },
      "source": [
        "### Shapley explanation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzrdl9YIfS-8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cfadd7c2-86b1-4bdb-9989-34194d4f2e23"
      },
      "source": [
        "intp.shap_exp(e, input1.detach(), img1)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'intp' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-272d22e0834f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mintp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshap_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'intp' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSW8zYH8ETt9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "bfbe24d8-e8f7-41b4-e0f8-7f1771923e5b"
      },
      "source": [
        "shap_values = e2.shap_values(input1.detach())\n",
        "shapley_values = [np.swapaxes(np.swapaxes(s, 2, 3), 1, -1) for s in shap_values]\n",
        "\n",
        "image11 = img1[np.newaxis, :]\n",
        "\n",
        "shap.image_plot(shapley_values, image11,  show=False)\n",
        "plt.suptitle(\"All channels together\");"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'e2' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-3dc727d4dfeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshap_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mshapley_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshap_values\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimage11\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'e2' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcA5fUFSOGpQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b668f835-970a-44b8-a941-72291eee3946"
      },
      "source": [
        "type(image11)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'image11' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-36fe1955acef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'image11' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UkaPvmWftF9",
        "colab_type": "text"
      },
      "source": [
        "### Hierarchical Shapley"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDQ_FdYlftNv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "43a11d62-633d-45db-b3a0-6d37f7cbdb51"
      },
      "source": [
        "\n",
        "a = 6.0\n",
        "f = np.linspace(0.7, 1.3, 30)\n",
        "l = (f*a).tolist()\n",
        "h.saliency_map(image1, label1, tolerance = l)\n",
        "h.saliency_map(image1, label1, tolerance = [6], only_one_run = True)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'h' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-3b9f8598b1e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaliency_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaliency_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monly_one_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'h' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LONuoeMizdD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For Hierarchical \n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "\n",
        "class HierarchicalShap2:\n",
        "    \"\"\"\n",
        "    Explains the salient regions of images according a given network.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model, background, mean=np.array([0.5, 0.5, 0.5]), sd=np.array([0.5, 0.5, 0.5])):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        model : the model from which you wish to study the decision\n",
        "        background : used to remove the contribution of non-considered regions when constructing subsets\n",
        "        mean : the mean used for image normalization (useful for plotting from input)\n",
        "        sd : the standard deviation used for normalization (useful for plotting from input)\n",
        "        \"\"\"\n",
        "        self.model = model\n",
        "        self.background = background\n",
        "        self.mean = mean\n",
        "        self.sd = sd\n",
        "\n",
        "    def display_cropped_images(self, images, scores):\n",
        "        \"\"\"\n",
        "        Draw the subsets.\n",
        "        Parameters\n",
        "        ----------\n",
        "        images : all the subsets to draw\n",
        "        scores : the output score for a class 1\n",
        "        \"\"\"\n",
        "        fig, axs = plt.subplots(4, 4, figsize=(15, 15))\n",
        "        for i in range(4):\n",
        "            for j in range(4):\n",
        "                im = images[4 * i + j].numpy().transpose(1, 2, 0)\n",
        "                im = im * self.sd + self.mean\n",
        "                axs[i, j].imshow(im)\n",
        "                axs[i, j].set_title(\"#%d score:%f \" % (4 * i + j, scores[4 * i + j]))\n",
        "\n",
        "    def construct_subsets(self, im, s=(0, 0), region_size=(None, None)):\n",
        "        \"\"\"\n",
        "        Construct the subsets of im: all possible image resulting from removing from im the content of 0, 1, 2, 3\n",
        "        or all 4 quadrants of the region defined by start and region_size .\n",
        "        Parameters\n",
        "        ----------\n",
        "        im : the image from which to extract subsets\n",
        "        s : the top left pixel coordinates of the region analyzed, a tuple of\n",
        "        region_size : the size of the region analyzed\n",
        "        Returns\n",
        "        --------\n",
        "        subsets : the list of 16 images\n",
        "        r_coord : a 2x2 array where each entry is a tuple of tuples; the first indicating the start\n",
        "                  of the region and the second its size\n",
        "        \"\"\"\n",
        "\n",
        "        m = (s[0] + region_size[0] // 2, s[1] + region_size[1] // 2)\n",
        "        e = (s[0] + region_size[0], s[1] + region_size[1])\n",
        "\n",
        "        top_left = (s, (m[0] - s[0], m[1] - s[1]))\n",
        "        top_right = ((s[0], m[1]), (m[0] - s[0], e[1] - m[1]))\n",
        "        bottom_left = ((m[0], s[1]), (e[0] - m[0], m[1] - s[1]))\n",
        "        bottom_right = (m, (e[0] - m[0], e[1] - m[1]))\n",
        "        r_coord = np.array([[top_left, top_right], [bottom_left, bottom_right]])\n",
        "\n",
        "        subsets_size = [16, im.shape[0], im.shape[1], im.shape[2]]\n",
        "\n",
        "        bg = self.background\n",
        "        # removing 0 features\n",
        "        im1234 = bg.clone()\n",
        "        im1234[:, s[0]:e[0], s[1]:e[1]] = im[:, s[0]:e[0], s[1]:e[1]]\n",
        "        # removing 1 feature\n",
        "        im234 = im1234.clone()\n",
        "        im234[:, s[0]:m[0], s[1]:m[1]] = bg[:, s[0]:m[0], s[1]:m[1]]\n",
        "        im134 = im1234.clone()\n",
        "        im134[:, s[0]:m[0], m[1]:e[1]] = bg[:, s[0]:m[0], m[1]:e[1]]\n",
        "        im124 = im1234.clone()\n",
        "        im124[:, m[0]:e[0], s[1]:m[1]] = bg[:, m[0]:e[0], s[1]:m[1]]\n",
        "        im123 = im1234.clone()\n",
        "        im123[:, m[0]:e[0], m[1]:e[1]] = bg[:, m[0]:e[0], m[1]:e[1]]\n",
        "        # removing 2 features\n",
        "        im34 = im234.clone()\n",
        "        im34[:, s[0]:m[0], m[1]:e[1]] = bg[:, s[0]:m[0], m[1]:e[1]]\n",
        "        im24 = im234.clone()\n",
        "        im24[:, m[0]:e[0], s[1]:m[1]] = bg[:, m[0]:e[0], s[1]:m[1]]\n",
        "        im23 = im234.clone()\n",
        "        im23[:, m[0]:e[0], m[1]:e[1]] = bg[:, m[0]:e[0], m[1]:e[1]]\n",
        "        im14 = im134.clone()\n",
        "        im14[:, m[0]:e[0], s[1]:m[1]] = bg[:, m[0]:e[0], s[1]:m[1]]\n",
        "        im13 = im134.clone()\n",
        "        im13[:, m[0]:e[0], m[1]:e[1]] = bg[:, m[0]:e[0], m[1]:e[1]]\n",
        "        im12 = im123.clone()\n",
        "        im12[:, m[0]:e[0], s[1]:m[1]] = bg[:, m[0]:e[0], s[1]:m[1]]\n",
        "        # removing 3 features\n",
        "        im4 = im34.clone()\n",
        "        im4[:, m[0]:e[0], s[1]:m[1]] = bg[:, m[0]:e[0], s[1]:m[1]]\n",
        "        im3 = im34.clone()\n",
        "        im3[:, m[0]:e[0], m[1]:e[1]] = bg[:, m[0]:e[0], m[1]:e[1]]\n",
        "        im2 = im24.clone()\n",
        "        im2[:, m[0]:e[0], m[1]:e[1]] = bg[:, m[0]:e[0], m[1]:e[1]]\n",
        "        im1 = im14.clone()\n",
        "        im1[:, m[0]:e[0], m[1]:e[1]] = bg[:, m[0]:e[0], m[1]:e[1]]\n",
        "        # removing 4\n",
        "        im_ = bg.clone()\n",
        "\n",
        "        subsets = torch.zeros(size=subsets_size)\n",
        "        subsets[0] = im1234\n",
        "        subsets[1] = im234\n",
        "        subsets[2] = im134\n",
        "        subsets[3] = im124\n",
        "        subsets[4] = im123\n",
        "        subsets[5] = im34\n",
        "        subsets[6] = im24\n",
        "        subsets[7] = im23\n",
        "        subsets[8] = im14\n",
        "        subsets[9] = im13\n",
        "        subsets[10] = im12\n",
        "        subsets[11] = im4\n",
        "        subsets[12] = im3\n",
        "        subsets[13] = im2\n",
        "        subsets[14] = im1\n",
        "        subsets[15] = im_\n",
        "\n",
        "        return subsets, r_coord\n",
        "\n",
        "    def subset_scores(self, sub, label):\n",
        "        \"\"\"\n",
        "        Compute the scores of each subset input.\n",
        "        Parameters\n",
        "        ----------\n",
        "        sub : the subsets of inputs\n",
        "        label : the class label - typically 1 -  in which we're interested.\n",
        "        Returns\n",
        "        --------\n",
        "        score : an array of the 16 scores for each input\n",
        "        \"\"\"\n",
        "        outputs = self.model(sub)\n",
        "        score = outputs[:, label].detach().numpy()\n",
        " \n",
        "        return score\n",
        "\n",
        "    def shapley_of_quadrants(self, score):\n",
        "        \"\"\"\n",
        "        Return a 2x2 array which contains the Shapley values associated with each quadrant\n",
        "        Parameters\n",
        "        ----------\n",
        "        score : the network evaluation for each subset\n",
        "        Returns\n",
        "        --------\n",
        "        shapley_coefficients : an array of the 16 scores for each input\n",
        "        \"\"\"\n",
        "\n",
        "        phi1 = (score[14] - score[15] + score[0] - score[1]) / 4 \\\n",
        "               + (score[8] - score[11] + score[9] - score[12] + score[10] - score[13]\n",
        "                  + score[2] - score[5] + score[3] - score[6] + score[4] - score[7]) / 12\n",
        "\n",
        "        phi2 = (score[13] - score[15] + score[0] - score[2]) / 4 \\\n",
        "               + (score[6] - score[11] + score[7] - score[12] + score[10] - score[14]\n",
        "                  + score[1] - score[5] + score[3] - score[8] + score[4] - score[9]) / 12\n",
        "\n",
        "        phi3 = (score[12] - score[15] + score[0] - score[3]) / 4 \\\n",
        "               + (score[5] - score[11] + score[9] - score[14] + score[7] - score[13]\n",
        "                  + score[2] - score[8] + score[1] - score[6] + score[4] - score[10]) / 12\n",
        "\n",
        "        phi4 = (score[11] - score[15] + score[0] - score[4]) / 4 \\\n",
        "               + (score[8] - score[14] + score[5] - score[12] + score[6] - score[13]\n",
        "                  + score[1] - score[7] + score[3] - score[10] + score[2] - score[9]) / 12\n",
        "\n",
        "        shapley_coefficients = np.array([[phi1, phi2], [phi3, phi4]])\n",
        "        return shapley_coefficients\n",
        "\n",
        "    def get_salient_regions(self, shapley_values, tol, regions):\n",
        "        \"\"\"\n",
        "        Determine which of the 4 quadrants are salient, i.e. have Shapley value larger than tol\n",
        "        Parameters\n",
        "        ----------\n",
        "        shapley_values : the Shapley coefficients associated with each quadrant\n",
        "        tol : the specified tolerance for a sub-region to be considered salient\n",
        "        regions : the coordinates associated with each quadrant\n",
        "        Returns\n",
        "        --------\n",
        "        srs : a list of the coordinates of the quadrants whose Shapley values were large enough\n",
        "        \"\"\"\n",
        "        srs = []\n",
        "        for i in range(len(shapley_values)):\n",
        "            for j in range(len(shapley_values[0])):\n",
        "                if shapley_values[i, j] > tol:\n",
        "                    srs.append(regions[i, j])\n",
        "        return srs\n",
        "\n",
        "    def display_salient(self, im, srs_coll, count, filename ):\n",
        "        \"\"\"\n",
        "        Determine which of the 4 quadrants are salient, i.e. have Shapley value larger than tol\n",
        "        Parameters\n",
        "        ----------\n",
        "        im : the original image, in input format\n",
        "        srs_coll : a collection of all regions deemed salient\n",
        "        count : a normalizing mask which determines how many time each pixel was given a chance to be salient\n",
        "        filename : name of the file to save the figure to\n",
        "        \"\"\"\n",
        "        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(45, 30))\n",
        "        sample_image = im.numpy().transpose(1, 2, 0)\n",
        "        count = count.transpose(1, 2, 0)\n",
        "        image = sample_image * self.sd + self.mean\n",
        "        ax1.imshow(image)\n",
        "        ax2.imshow(image)\n",
        "        mask = np.zeros(image.shape)\n",
        "\n",
        "        # Count how many time each pixel was found to be in a salient region\n",
        "        for srs in srs_coll:\n",
        "            for sr in srs:\n",
        "                start = sr[0]\n",
        "                q_size = sr[1]\n",
        "\n",
        "                xs = [start[1], start[1] + q_size[1], start[1] + q_size[1], start[1]]\n",
        "                ys = [start[0], start[0], start[0] + q_size[0], start[0] + q_size[0]]\n",
        "                ax2.fill(xs, ys, 'r', alpha=1 / len(srs_coll))\n",
        "                mask[start[0]:start[0] + q_size[0], start[1]:start[1] + q_size[1], :] += np.ones(\n",
        "                    (q_size[0], q_size[1], 3))\n",
        "\n",
        "        # Normalize the mask by the number of tries in each region\n",
        "        mask /= count\n",
        "        # Normalize the mask to the range (0,1)\n",
        "        mask /= np.max(mask)\n",
        "        # Set to 0 elements smaller than 1/3\n",
        "        negligible = (mask < 1/3)\n",
        "        mask[negligible] = 0\n",
        "\n",
        "        ax1.set_xlim([0, im.shape[2]])\n",
        "        ax1.set_ylim([im.shape[1], 0])\n",
        "        ax2.set_xlim([0, im.shape[2]])\n",
        "        ax2.set_ylim([im.shape[1], 0])\n",
        "        ax3.imshow(image * mask)\n",
        "        if filename != None:\n",
        "            plt.savefig(filename, dpi=300)\n",
        "        return mask\n",
        "\n",
        "    def do_all(self, im, label, start, region_size, tol, debug=False):\n",
        "        \"\"\"\n",
        "        Secondary main loop: do everything for one region of the image.\n",
        "        ----------\n",
        "        im : the input image\n",
        "        start : the starting coordinates of the region\n",
        "        region_size : self-explanatory\n",
        "        tol : the specified tolerance for a sub-region to be considered salient\n",
        "        debug : if True, all subsets, there associated scores and the Shapley values will be displayed\n",
        "        Returns\n",
        "        --------\n",
        "        srs : a list of the coordinates of the quadrants whose Shapley values were large enough\n",
        "        \"\"\"\n",
        "        images_final, regions = self.construct_subsets(im, start, region_size)\n",
        "        score = self.subset_scores(images_final, label)\n",
        "        sm = self.shapley_of_quadrants(score)\n",
        "        if debug:\n",
        "            self.display_cropped_images(images_final, score)\n",
        "            f = plt.figure()\n",
        "            sns.heatmap(sm)\n",
        "            f.suptitle(\"Shap values of each quadrant\")\n",
        "\n",
        "        srs = self.get_salient_regions(sm, tol, regions)\n",
        "\n",
        "        return srs\n",
        "\n",
        "    def saliency_map(self, image, label, tolerance, only_one_run=False, debug=False, max_depth=30, filename=None):\n",
        "        \"\"\"\n",
        "        Create and then show a saliency map built with the Hierarchical Shapley method.\n",
        "        ----------\n",
        "        im : the input image\n",
        "        label : the label with respect to which we want to analyze - typically 1\n",
        "        tolerance : the specified tolerance for a sub-region to be considered salient. A list is expected.\n",
        "        only_one_run : when False, several runs are done by also considering 16 cropped versions of the input\n",
        "        debug : if True, all subsets, there associated scores and the Shapley values will be displayed\n",
        "        max_depth : the maximum number of divisions you want to allow before deciding the tolerance is too low.\n",
        "        filename : name of the file to save the figure to\n",
        "        \"\"\"\n",
        "        ls = []\n",
        "        count = np.ones(image.shape)\n",
        "        xf = [image.shape[1], image.shape[2]]\n",
        "\n",
        "\n",
        "        start = (0,0)\n",
        "        end = (xf[0], xf[1])\n",
        "        size = (end[0] - start[0], end[1] - start[1])\n",
        "        lx, ly = image.shape[1], image.shape[2]\n",
        "        dx, dy = image.shape[1]//4, image.shape[2]//4\n",
        "       \n",
        "        def salient_regions(I, sx, sy): \n",
        "          srs = [(start, size)]\n",
        "          finished = []\n",
        "          k = 0\n",
        "          while len(srs) > 0:\n",
        "            all_ = []\n",
        "            for sr in srs:\n",
        "                s = self.do_all(I, label, sr[0], sr[1], tolerance, debug)\n",
        "                if s == []:\n",
        "\n",
        "                    coords = [sr[0][0] + sx, sr[0][1] + sy]\n",
        "                    finished.append(((coords), (sr[1])))\n",
        "                else:\n",
        "                    all_ += s\n",
        "            srs = all_\n",
        "            k += 1\n",
        "          return finished\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "        # normal\n",
        "        ls.append(salient_regions(image, 0, 0))\n",
        "        \n",
        "        # shifted to bottom right \n",
        "        image_br = self.background.clone()\n",
        "        image_br[:, :lx-dx, :ly-dy] = image[:, dx:, dy:]\n",
        "        ls.append(salient_regions(image_br, dx, dy))\n",
        "          \n",
        "         # shifted to bottom left \n",
        "        image_bl = self.background.clone()\n",
        "        image_bl[:, :lx-dx, dy:] = image[:, dx:, :ly-dy]\n",
        "        ls.append(salient_regions(image_bl, dx, -dy))\n",
        "\n",
        "        # shifted to top left \n",
        "        image_tl = self.background.clone()\n",
        "        image_tl[:, dx:, dy:] = image[:, :lx-dx, :ly-dy]\n",
        "        ls.append(salient_regions(image_tl, -dx, -dy))\n",
        "\n",
        "        # shifted to top right \n",
        "        image_tr = self.background.clone()\n",
        "        image_tr[:, dx:, :ly-dy] = image[:, :lx-dx, dy:]\n",
        "        ls.append(salient_regions(image_tr, -dx, dy))\n",
        "\n",
        "\n",
        "        return self.display_salient(image, ls, count, filename)\n",
        "\n",
        "\n",
        "average = torch.mean(X, dim = 0)\n",
        "h2 = HierarchicalShap2(net, background = average)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'seaborn'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-c9db2f6e9a71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFFhzNTJhb1x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "outputId": "b7875790-b749-4ab4-945f-72fa63d4a1de"
      },
      "source": [
        "\n",
        "h2.saliency_map(image1, label1, tolerance = [6], only_one_run = False);\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'h2' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-42a151f11124>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mh2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaliency_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monly_one_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'h2' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSbL5u5PKF0R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "41b4917f-930d-417d-c7de-de992627133a"
      },
      "source": [
        "h.saliency_map(image1, label1, tolerance = [6], only_one_run = False);"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'h' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-595f7f3a6b6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaliency_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monly_one_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'h' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MYVJhXmH-Mw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def saliency_map(self, image, label, tolerance, only_one_run=False, debug=False, max_depth=30, filename=None):\n",
        "        \"\"\"\n",
        "        Create and then show a saliency map built with the Hierarchical Shapley method.\n",
        "        ----------\n",
        "        im : the input image\n",
        "        label : the label with respect to which we want to analyze - typically 1\n",
        "        tolerance : the specified tolerance for a sub-region to be considered salient. A list is expected.\n",
        "        only_one_run : when False, several runs are done by also considering 16 cropped versions of the input\n",
        "        debug : if True, all subsets, there associated scores and the Shapley values will be displayed\n",
        "        max_depth : the maximum number of divisions you want to allow before deciding the tolerance is too low.\n",
        "        filename : name of the file to save the figure to\n",
        "        \"\"\"\n",
        "        ls = []\n",
        "        count = np.ones(image.shape)\n",
        "        xf = [image.shape[1], image.shape[2]]\n",
        "\n",
        "\n",
        "        start = (0,0)\n",
        "        end = (xf[0], xf[1])\n",
        "        size = (end[0] - start[0], end[1] - start[1])\n",
        "        lx, ly = image.shape[1], image.shape[2]\n",
        "        dx, dy = image.shape[1]//4, image.shape[2]//4\n",
        "       \n",
        "        def salient_regions(I, sx, sy): \n",
        "          srs = [(start, size)]\n",
        "          finished = []\n",
        "          k = 0\n",
        "          while len(srs) > 0:\n",
        "            all_ = []\n",
        "            for sr in srs:\n",
        "                s = self.do_all(I, label, sr[0], sr[1], tolerance, debug)\n",
        "                if s == []:\n",
        "                    coords = [sr[0][0] + sx, sr[0][1] + sy]\n",
        "                    finished.append(((coords), (sr[1])))\n",
        "                else:\n",
        "                    all_ += s\n",
        "                srs = all_\n",
        "                k += 1\n",
        "            return finished\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "        # normal\n",
        "        ls.append(salient_regions(image, 0, 0))\n",
        "        \n",
        "        # shifted to bottom right \n",
        "        image_br = self.background.clone()\n",
        "        image_br[:, :lx-dx, :ly-dy] = image[:, dx:, dy:]\n",
        "        ls.append(salient_regions(image_br, dx, dy))\n",
        "          \n",
        "         # shifted to bottom left \n",
        "        image_bl = self.background.clone()\n",
        "        image_bl[:, :lx-dx, dy:] = image[:, dx:, :ly-dy]\n",
        "        ls.append(salient_regions(image_bl, dx, -dy))\n",
        "\n",
        "        # shifted to top left \n",
        "        image_tl = self.background.clone()\n",
        "        image_tl[:, dx:, dy:] = image[:, :lx-dx, :ly-dy]\n",
        "        ls.append(salient_regions(image_tl, -dx, -dy))\n",
        "\n",
        "        # shifted to top right \n",
        "        image_tr = self.background.clone()\n",
        "        image_tr[:, dx:, :ly-dy] = image[:, :lx-dx, dy:]\n",
        "        ls.append(salient_regions(image_tr, -dx, dy))\n",
        "\n",
        "\n",
        "        return self.display_salient(image, ls, count, filename)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63-8OVM-jR-l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "efc43793-e3f8-48f4-cd33-da539cd8d6c5"
      },
      "source": [
        "train_data = ImageFolder(root = os.path.join(root_dir, 'train'), transform = transf)\n",
        "dataloader = DataLoader(train_data, batch_size = Batch_Size, shuffle = True, num_workers = 0)\n",
        "train_loader = iter(dataloader)\n",
        "\n",
        "images, labels = next(train_loader)\n",
        "i = 0\n",
        "\n",
        "for i in range(20):\n",
        "  image = images[i]\n",
        "  label = labels[i]\n",
        "\n",
        "  input_ = image.view(-1, 3, 100, 120) # This shape is necessary for the network \n",
        "  output = net(input_)\n",
        "  _, predicted = torch.max(output.data, 1)\n",
        "  a = output.data[0][1].detach().numpy()\n",
        "  img = utils.input2image(image, MEAN, STD)\n",
        "  utils.display_image(img, a, int(predicted))\n",
        "  \n",
        "\n",
        "  if (a > 0):\n",
        "    h.saliency_map(image, label, tolerance = l, only_one_run = False)\n",
        "  i += 1"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'os' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-999673ba5ce5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatch_Size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ]
    }
  ]
}