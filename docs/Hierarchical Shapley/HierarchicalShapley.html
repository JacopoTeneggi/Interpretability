<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.8.3" />
<title>Hierarchical Shapley.HierarchicalShapley API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js" integrity="sha256-eOgo0OtLL4cdq7RdwRUiGKLX9XsIJ7nGhWEKbohmVAQ=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>Hierarchical Shapley.HierarchicalShapley</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import torch
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns


class HierarchicalShap:
    &#34;&#34;&#34;
    Explains the salient regions of images according a given network using a hierarchical method based on Shapley values. 
    &#34;&#34;&#34;

    def __init__(self, model, background, mean=np.array([0.5, 0.5, 0.5]), sd=np.array([0.5, 0.5, 0.5])):
        &#34;&#34;&#34; Initialize the explanation model. 
        
        Parameters
        ----------
        model : a torch neural network (typically torch.nn.Module or a subclass of it)
            the model whose decisions you wish to study
        background : torch tensor 
            used to remove the contribution of non-considered regions when constructing subsets
        mean : array of shape (3,)
            the mean of each channel in the dataset, used for image normalization (useful for plotting from input)
        sd : array of shape (3,)
            the standard deviation of each channel in the dataset, used for normalization (useful for plotting from input)
        &#34;&#34;&#34;
        
        self.model = model
        self.background = background
        self.mean = mean
        self.sd = sd

    def display_cropped_images(self, images, scores):
        &#34;&#34;&#34; Draw the subsets (images resulting from removing certain quadrants).
        
        Parameters
        ----------
        images : torch tensor
            all the subsets to draw
        scores : numpy array of shape (16,)
            the scores for each input
        &#34;&#34;&#34;
        
        fig, axs = plt.subplots(4, 4, figsize=(15, 15))
        for i in range(4):
            for j in range(4):
                im = images[4 * i + j].numpy().transpose(1, 2, 0)
                im = im * self.sd + self.mean
                axs[i, j].imshow(im)
                axs[i, j].set_title(&#34;#%d score:%f &#34; % (4 * i + j, scores[4 * i + j]))

    def construct_subsets(self, im, s=(0, 0), region_size=(None, None)):
        &#34;&#34;&#34; Construct the subsets of im: all possible image resulting from removing from im the content of 0, 1, 2, 3
        or all 4 quadrants of the region defined by start and region_size.
        
        Parameters
        ----------
        im : torch tensor 
            the input image
        s : tuple of ints
            the top left pixel coordinates of the region analyzed
        region_size : tuple of ints
            the size of the region analyzed
        
        Returns
        --------
        subsets : the list of 16 images
        r_coord : a 2x2 array where each entry is a tuple of tuples; the first indicating the start
                  of the region and the second its size
        &#34;&#34;&#34;

        m = (s[0] + region_size[0] // 2, s[1] + region_size[1] // 2)
        e = (s[0] + region_size[0], s[1] + region_size[1])

        top_left = (s, (m[0] - s[0], m[1] - s[1]))
        top_right = ((s[0], m[1]), (m[0] - s[0], e[1] - m[1]))
        bottom_left = ((m[0], s[1]), (e[0] - m[0], m[1] - s[1]))
        bottom_right = (m, (e[0] - m[0], e[1] - m[1]))
        r_coord = np.array([[top_left, top_right], [bottom_left, bottom_right]])

        subsets_size = [16, im.shape[0], im.shape[1], im.shape[2]]

        bg = self.background
        # removing 0 features
        im1234 = bg.clone()
        im1234[:, s[0]:e[0], s[1]:e[1]] = im[:, s[0]:e[0], s[1]:e[1]]
        # removing 1 feature
        im234 = im1234.clone()
        im234[:, s[0]:m[0], s[1]:m[1]] = bg[:, s[0]:m[0], s[1]:m[1]]
        im134 = im1234.clone()
        im134[:, s[0]:m[0], m[1]:e[1]] = bg[:, s[0]:m[0], m[1]:e[1]]
        im124 = im1234.clone()
        im124[:, m[0]:e[0], s[1]:m[1]] = bg[:, m[0]:e[0], s[1]:m[1]]
        im123 = im1234.clone()
        im123[:, m[0]:e[0], m[1]:e[1]] = bg[:, m[0]:e[0], m[1]:e[1]]
        # removing 2 features
        im34 = im234.clone()
        im34[:, s[0]:m[0], m[1]:e[1]] = bg[:, s[0]:m[0], m[1]:e[1]]
        im24 = im234.clone()
        im24[:, m[0]:e[0], s[1]:m[1]] = bg[:, m[0]:e[0], s[1]:m[1]]
        im23 = im234.clone()
        im23[:, m[0]:e[0], m[1]:e[1]] = bg[:, m[0]:e[0], m[1]:e[1]]
        im14 = im134.clone()
        im14[:, m[0]:e[0], s[1]:m[1]] = bg[:, m[0]:e[0], s[1]:m[1]]
        im13 = im134.clone()
        im13[:, m[0]:e[0], m[1]:e[1]] = bg[:, m[0]:e[0], m[1]:e[1]]
        im12 = im123.clone()
        im12[:, m[0]:e[0], s[1]:m[1]] = bg[:, m[0]:e[0], s[1]:m[1]]
        # removing 3 features
        im4 = im34.clone()
        im4[:, m[0]:e[0], s[1]:m[1]] = bg[:, m[0]:e[0], s[1]:m[1]]
        im3 = im34.clone()
        im3[:, m[0]:e[0], m[1]:e[1]] = bg[:, m[0]:e[0], m[1]:e[1]]
        im2 = im24.clone()
        im2[:, m[0]:e[0], m[1]:e[1]] = bg[:, m[0]:e[0], m[1]:e[1]]
        im1 = im14.clone()
        im1[:, m[0]:e[0], m[1]:e[1]] = bg[:, m[0]:e[0], m[1]:e[1]]
        # removing 4
        im_ = bg.clone()

        subsets = torch.zeros(size=subsets_size)
        subsets[0] = im1234
        subsets[1] = im234
        subsets[2] = im134
        subsets[3] = im124
        subsets[4] = im123
        subsets[5] = im34
        subsets[6] = im24
        subsets[7] = im23
        subsets[8] = im14
        subsets[9] = im13
        subsets[10] = im12
        subsets[11] = im4
        subsets[12] = im3
        subsets[13] = im2
        subsets[14] = im1
        subsets[15] = im_

        return subsets, r_coord

    def subset_scores(self, sub, label):
        &#34;&#34;&#34; Compute the scores of each subset input.
        
        Parameters
        ----------
        sub : the subsets of inputs
        label : the class label - typically 1 -  in which we&#39;re interested.
        
        Returns
        --------
        score : numpy array of shape (16,)
            the scores for each input
        &#34;&#34;&#34;
        
        outputs = self.model(sub)
        score = outputs[:, label].detach().numpy()

        return score

    def shapley_of_quadrants(self, score):
        &#34;&#34;&#34; Compute the Shapley values associated with each quadrant.
        
        Parameters
        ----------
        score : the network evaluation for each subset
        
        Returns
        --------
        shapley_coefficients : array of shape (2,2) 
            the shapley coefficients of each quadrant
        &#34;&#34;&#34;

        phi1 = (score[14] - score[15] + score[0] - score[1]) / 4\
               + (score[8] - score[11] + score[9] - score[12] + score[10] - score[13]
                  + score[2] - score[5] + score[3] - score[6] + score[4] - score[7]) / 12

        phi2 = (score[13] - score[15] + score[0] - score[2]) / 4 \
               + (score[6] - score[11] + score[7] - score[12] + score[10] - score[14]
                  + score[1] - score[5] + score[3] - score[8] + score[4] - score[9]) / 12

        phi3 = (score[12] - score[15] + score[0] - score[3]) / 4 \
               + (score[5] - score[11] + score[9] - score[14] + score[7] - score[13]
                  + score[2] - score[8] + score[1] - score[6] + score[4] - score[10]) / 12

        phi4 = (score[11] - score[15] + score[0] - score[4]) / 4 \
               + (score[8] - score[14] + score[5] - score[12] + score[6] - score[13]
                  + score[1] - score[7] + score[3] - score[10] + score[2] - score[9]) / 12

        shapley_coefficients = np.array([[phi1, phi2], [phi3, phi4]])
        
        return shapley_coefficients

    def get_salient_regions(self, shapley_values, tol, regions):
        &#34;&#34;&#34; Determine which of the 4 quadrants are salient, i.e. have Shapley value larger than tol.
        
        Parameters
        ----------
        shapley_values : array of shape (2,2) 
            the shapley coefficients of each quadrant
        tol : float 
            the specified tolerance for a sub-region to be considered salient
        regions : the coordinates associated with each quadrant
        
        Returns
        --------
        srs : list of tuples of tuples of ints 
            a list of all salient regions (a tuple with start coordinates, size), i.e. regions whose Shapley values were large enough
        &#34;&#34;&#34;
        
        srs = []
        for i in range(len(shapley_values)):
            for j in range(len(shapley_values[0])):
                if shapley_values[i, j] &gt; tol:
                    srs.append(regions[i, j])

        return srs

    def display_salient(self, im, srs_coll, count, filename):
        &#34;&#34;&#34; Determine which of the 4 quadrants are salient, i.e. have Shapley value larger than tol.
        
        Parameters
        ----------
        im : torch tensor 
            the input image
        srs_coll : a collection of all regions deemed salient
        count : numpy array
            a normalizing mask which determines how many time each pixel was given a chance to be counted as salient
        filename : string 
            name of the file to save the figure
        
        Returns
        -------
        mask : numpy array 
            the saliency map 
        &#34;&#34;&#34;
        
        fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(60, 30))

        sample_image = im.numpy().transpose(1, 2, 0)
        count = count.transpose(1, 2, 0)
        ax4.imshow(count / np.max(count))
        image = sample_image * self.sd + self.mean
        ax1.imshow(image)
        ax2.imshow(image)
        mask = np.zeros(image.shape)

        # Count how many time each pixel was found to be in a salient region
        for srs in srs_coll:
            for sr in srs:
                start = sr[0]
                q_size = sr[1]
                xs = [start[1], start[1] + q_size[1], start[1] + q_size[1], start[1]]
                ys = [start[0], start[0], start[0] + q_size[0], start[0] + q_size[0]]
                ax2.fill(xs, ys, &#39;r&#39;, alpha=1 / len(srs_coll))

                mask[start[0]:start[0] + q_size[0], start[1]:start[1] + q_size[1], :] += np.ones(
                    (q_size[0], q_size[1], 3))

        # Normalize the mask by the number of tries in each region
        mask /= count
        # Normalize the mask to the range (0,1)
        mask /= np.max(mask)
        # Set to 0 elements smaller than 1/5
        negligible = (mask &lt; 1 / 5)
        mask[negligible] = 0

        ax1.set_xlim([0, im.shape[2]])
        ax1.set_ylim([im.shape[1], 0])
        ax2.set_xlim([0, im.shape[2]])
        ax2.set_ylim([im.shape[1], 0])
        ax3.imshow(image * mask)
        if filename != None:
            plt.savefig(filename, dpi=300)
        return mask

    def do_all(self, im, label, start, region_size, tol, debug=False):
        &#34;&#34;&#34; Secondary main loop: do everything for one region of the image.
        
        Parameters
        ----------
        im : torch tensor 
            the input image
        start : tuple of ints
            the starting coordinates of the region
        region_size : tuple of ints
            size of the region
        tol : float
            the specified tolerance for a sub-region to be considered salient
        debug : bool 
            if True, all subsets, there associated scores and the Shapley values will be displayed
            
        Returns
        --------
        srs : list of tuples of tuples of ints 
            a list of all salient regions (a tuple with start coordinates, size), i.e. regions whose Shapley values were large enough
        &#34;&#34;&#34;
        
        images_final, regions = self.construct_subsets(im, start, region_size)
        score = self.subset_scores(images_final, label)
        sm = self.shapley_of_quadrants(score)
        if debug:
            self.display_cropped_images(images_final, score)
            f = plt.figure()
            sns.heatmap(sm)
            f.suptitle(&#34;Shap values of each quadrant&#34;)

        srs = self.get_salient_regions(sm, tol, regions)

        return srs

    def saliency_map(self, image, label, tolerance, only_one_run=False, debug=False, max_depth=30, filename=None):
        &#34;&#34;&#34; Create and then show a saliency map built with the Hierarchical Shapley method.
        
        Parameters
        ----------
        image : torch tensor 
            the input image
        label : int in {0,1}
            the label with respect to which we want to analyze - typically 1
        tolerance : float
            the specified tolerance for a sub-region to be considered salient. A list is expected.
        only_one_run : bool
            when False, several runs are done by also considering 16 cropped versions of the input
        debug : bool
            if True, all subsets, there associated scores and the Shapley values will be displayed
        max_depth : int
            the maximum number of divisions you want to allow before deciding the tolerance is too low.
        filename : string
            name of the file to save the figure to
        
        Returns
        -------
        mask : numpy array
            the saliency map 
        &#34;&#34;&#34;
        
        ls = []
        count = np.zeros(image.shape)
        xf = [image.shape[1], image.shape[2]]

        if only_one_run:
            starts = [(0, 0)]
            ends = [(xf[0], xf[1])]
        else:
            delta = [image.shape[1] // 20, image.shape[2] // 24]
            starts = [(0, 0), (0, delta[1]), (delta[0], 0), (delta[0], delta[1])]
            ends = [(xf[0], xf[1]), (xf[0], xf[1] - delta[1]), (xf[0] - delta[0], xf[1]),
                    (xf[0] - delta[0], xf[1] - delta[1])]

        for start in starts:
            for end in ends:
                size = (end[0] - start[0], end[1] - start[1])
                count[:, start[0]:end[0], start[1]:end[1]] += np.ones((3, size[0], size[1]))

        for tol in tolerance:
            try:
                for start in starts:
                    for end in ends:

                        size = (end[0] - start[0], end[1] - start[1])
                        srs = [(start, size)]
                        finished = []
                        k = 0

                        while len(srs) &gt; 0:

                            if k &gt; max_depth:
                                raise RuntimeError(&#34;Depth %d reached at tolerance %f&#34; % (k, tol))
                            all_ = []
                            for sr in srs:
                                s = self.do_all(image, label, sr[0], sr[1], tol, debug)
                                if s == []:
                                    finished.append(((sr[0]), (sr[1])))

                                else:
                                    all_ += s
                            srs = all_
                            k += 1
                        ls.append(finished)
            except RuntimeError as w:
                print(w, &#34;Run ignored, consider increasing tolerance.&#34;)

        mask = self.display_salient(image, ls, count, filename)
        return mask

    def get_salient_regions_optim_tol(self, shapley_values, tols, regions):
        &#34;&#34;&#34; Determine which of the 4 quadrants are salient, i.e. have Shapley value larger than tol.
        
        Parameters
        ----------
        shapley_values : array of shape (2,2)
            the Shapley coefficients associated with each quadrant
        tol : float
            the specified tolerance for a sub-region to be considered salient
        regions : the coordinates associated with each quadrant
        
        Returns
        --------
        srs : list of tuples of tuples of ints 
            a list of all salient regions (a tuple with start coordinates, size), i.e. regions whose Shapley values were large enough
        &#34;&#34;&#34;
        
        srs = [[] for r in range(len(tols))]
        for i in range(len(shapley_values)):
            for j in range(len(shapley_values[0])):
                for r in range(len(tols)):
                    if shapley_values[i, j] &gt; tols[r]:
                        srs[r].append(regions[i, j])
        return srs

    def do_all_optim_tol(self, im, label, start, region_size, tols, debug=False):
        &#34;&#34;&#34; Secondary main loop: do everything for one region of the image, in a way that is optimal when using several tolerances 
        
        Parameters
        ----------
        im : torch tensor 
            the input image
        start : tuple of ints
            the starting coordinates of the region
        region_size : tuple of ints
            size of the region
        tol : float or list of flaots
            the specified tolerance for a sub-region to be considered salient
        debug : bool
            if True, all subsets, there associated scores and the Shapley values will be displayed
            
        Returns
        --------
        srs : list of tuples of tuples of ints 
            a list of all salient regions (a tuple with start coordinates, size), i.e. regions whose Shapley values were large enough
        &#34;&#34;&#34;
        
        images_final, regions = self.construct_subsets(im, start, region_size)
        score = self.subset_scores(images_final, label)
        sm = self.shapley_of_quadrants(score)
        if debug:
            self.display_cropped_images(images_final, score)
            f = plt.figure()
            sns.heatmap(sm)
            f.suptitle(&#34;Shap values of each quadrant&#34;)

        srs = self.get_salient_regions_optim_tol(sm, tols, regions)

        return srs

    def saliency_map_optim_tol(self, image, label, tolerance, only_one_run=False, debug=False, max_depth=30,
                               filename=None):
        &#34;&#34;&#34; Create and then show a saliency map built with the Hierarchical Shapley method (optimized for when using a list of tolerances).
        
        Parameters
        ----------
        im : torch tensor 
            the input image
        label : int in {0,1}
            the label with respect to which we want to analyze - typically 1
        tolerance : float or list of floats
            the specified tolerance for a sub-region to be considered salient. A list is expected.
        only_one_run : bool 
            when False, several runs are done by also considering 16 cropped versions of the input
        debug : bool, optional 
            if True, all subsets, there associated scores and the Shapley values will be displayed
        max_depth : int, optional 
            the maximum number of divisions you want to allow before deciding the tolerance is too low.
        filename : string, optional 
            name of the file to save the figure to
        
        Returns
        -------
        mask : numpy array
            the saliency map 
        &#34;&#34;&#34;
        
        ls = []
        count = np.zeros(image.shape)
        xf = [image.shape[1], image.shape[2]]

        if only_one_run:
            starts = [(0, 0)]
            ends = [(xf[0], xf[1])]
        else:
            delta = [image.shape[1] // 20, image.shape[2] // 24]
            starts = [(0, 0), (0, delta[1]), (delta[0], 0), (delta[0], delta[1])]
            ends = [(xf[0], xf[1]), (xf[0], xf[1] - delta[1]), (xf[0] - delta[0], xf[1]),
                    (xf[0] - delta[0], xf[1] - delta[1])]

        for start in starts:
            for end in ends:
                size = (end[0] - start[0], end[1] - start[1])
                count[:, start[0]:end[0], start[1]:end[1]] += np.ones((3, size[0], size[1]))

        for start in starts:
            for end in ends:

                size = (end[0] - start[0], end[1] - start[1])
                srs = [[(start, size)] for r in range(len(tolerance))]
                finished = [[] for r in range(len(tolerance))]
                was_finished = [True for r in range(len(tolerance))]
                k = 0

                while len(srs[0]) &gt; 0 and k &lt; max_depth:
                    all_ = [[] for r in range(len(tolerance))]

                    for sr in srs[0]:
                        s = self.do_all_optim_tol(image, label, sr[0], sr[1], tolerance, debug)

                        for r in range(len(tolerance)):
                            if len(srs[r]) &gt; 0:
                                if s[r] == []:
                                    finished[r].append(((sr[0]), (sr[1])))
                                else:
                                    all_[r] += s[r]

                    for r in range(len(tolerance)):
                        srs[r] = all_[r]

                    k += 1

                for r in range(len(tolerance)):
                    if len(srs[r]) == 0:
                        ls.append(finished[r])
                    else:
                        print(&#34;Max depth of %d reached at tolerance %.3f&#34; % (max_depth, tolerance[r]))

        mask = self.display_salient(image, ls, count, filename)
        return mask
    
    def saliency_map_optim_rand(self, image, label, tolerance, debug=False, max_depth=30, filename=None):
        &#34;&#34;&#34; Create and then show a saliency map built with the Hierarchical Shapley method 
        (optimized for using several cropped versions of the original input). 
        
        Parameters
        ----------
        im : torch tensor 
            the input image
        label : int in {0,1}
            the label with respect to which we want to analyze - typically 1
        tolerance : float or list of floats
            the tolerance for a sub-region to be considered salient. A list is expected.
        only_one_run : bool 
            when False, several runs are done by also considering 16 cropped versions of the input
        debug : bool 
            if True, all subsets, there associated scores and the Shapley values will be displayed
        max_depth : int
            the maximum number of divisions you want to allow before deciding the tolerance is too low.
        filename : string 
            name of the file to save the figure to
            
        Returns
        -------
        mask : numpy array
            the saliency map 
        &#34;&#34;&#34;
        
        ls = []

        xf = [image.shape[1], image.shape[2]]

        start = (0, 0)
        end = (xf[0], xf[1])
        size = (end[0] - start[0], end[1] - start[1])
        lx, ly = image.shape[1], image.shape[2]
        dx, dy = image.shape[1] // 4, image.shape[2] // 4

        def salient_regions(I, sx, sy):
            &#34;&#34;&#34; Get salient regions of image I, knowing that it has been shifted by sx and sy from the original input. &#34;&#34;&#34;
            
            finished = []

            for tol in tolerance:
                k = 0
                srs = [(start, size)]
                current = []
                while len(srs) &gt; 0 and k &lt; max_depth:
                    all_ = []
                    for sr in srs:
                        s = self.do_all(I, label, sr[0], sr[1], tol, debug)
                        if s == []:
                            coords = np.array([sr[0][0] + sx, sr[0][1] + sy])
                            current.append((coords, sr[1]))
                        else:
                            all_ += s
                    srs = all_
                    k += 1
                if (k &lt; max_depth):
                    finished += current
            return finished

        # normal
        a = salient_regions(image, 0, 0)
        ls.append(a)
        count = np.ones(image.shape)

        # shifted to bottom right
        image_br = self.background.clone()
        image_br[:, :lx - dx, :ly - dy] = image[:, dx:, dy:]
        ls.append(salient_regions(image_br, dx, dy))
        count[:, dx:, dy:] += np.ones((3, lx - dx, ly - dy))

        # shifted to bottom left
        image_bl = self.background.clone()
        image_bl[:, :lx - dx, dy:] = image[:, dx:, :ly - dy]
        ls.append(salient_regions(image_bl, dx, -dy))
        count[:, dx:, :ly - dy] += np.ones((3, lx - dx, ly - dy))

        # shifted to top left
        image_tl = self.background.clone()
        image_tl[:, dx:, dy:] = image[:, :lx - dx, :ly - dy]
        ls.append(salient_regions(image_tl, -dx, -dy))
        count[:, :lx - dx, :ly - dy] += np.ones((3, lx - dx, ly - dy))

        # shifted to top right
        image_tr = self.background.clone()
        image_tr[:, dx:, :ly - dy] = image[:, :lx - dx, dy:]
        ls.append(salient_regions(image_tr, -dx, dy))
        count[:, :lx - dx, dy:] += np.ones((3, lx - dx, ly - dy))

        mask = self.display_salient_optim_rand(image, ls, count, filename)
        return mask

    def display_salient_optim_rand(self, im, srs_coll, count, filename):
        &#34;&#34;&#34; Determine which of the 4 quadrants are salient, i.e. have Shapley value larger than tol
        (optimized for using several cropped versions of the original input). 
        
        Parameters
        ----------
        im : torch tensor 
            the input image
        srs_coll : a collection of all regions deemed salient
        count : numpy array
            a normalizing mask which determines how many time each pixel was given a chance to be salient
        filename : string 
            name of the file to save the figure to
        
        Returns
        -------
        mask : numpy array
            the saliency map 
        &#34;&#34;&#34;
        
        fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(60, 30))

        sample_image = im.numpy().transpose(1, 2, 0)
        count = count.transpose(1, 2, 0)
        ax4.imshow(count / np.max(count))
        image = sample_image * self.sd + self.mean
        ax1.imshow(image)
        ax2.imshow(image)
        mask = np.zeros(image.shape)

        # Count how many time each pixel was found to be in a salient region
        for srs in srs_coll:
            for sr in srs:
                start = sr[0]
                q_size = sr[1]

                if (start[0] &gt;= 0 and start[0] + q_size[0] &lt;= image.shape[0] and start[1] &gt;= 0 and start[1] + q_size[
                    1] &lt;= image.shape[1]):
                    xs = [start[1], start[1] + q_size[1], start[1] + q_size[1], start[1]]
                    ys = [start[0], start[0], start[0] + q_size[0], start[0] + q_size[0]]
                    ax2.fill(xs, ys, &#39;r&#39;, alpha=1 / len(srs_coll))

                    mask[start[0]:start[0] + q_size[0], start[1]:start[1] + q_size[1], :] += np.ones(
                        (q_size[0], q_size[1], 3))

        # Normalize the mask by the number of tries in each region
        mask /= count
        # Normalize the mask to the range (0,1)
        mask /= np.max(mask)
        # Set to 0 elements smaller than 1/5
        negligible = (mask &lt; 1 / 5)
        mask[negligible] = 0

        ax1.set_xlim([0, im.shape[2]])
        ax1.set_ylim([im.shape[1], 0])
        ax2.set_xlim([0, im.shape[2]])
        ax2.set_ylim([im.shape[1], 0])
        ax3.imshow(image * mask)
        if filename != None:
            plt.savefig(filename, dpi=300)
        return mask

    def get_list_optim_tol(self, image, label, tolerance, sx, sy, debug=False, max_depth=30):
        &#34;&#34;&#34; Create and then show a saliency map built with the Hierarchical Shapley method
        (optimized for using several cropped version of the initial input and several tolerance thresholds).
        
        Parameters
        ----------
        image : torch tensor 
            the input image
        label : int in {0,1}
            the label with respect to which we want to analyze - typically 1
        tolerance : float or list of floats
            the specified tolerance for a sub-region to be considered salient. A list is expected.
        sx : int
            shift in the x-coordinate of image with respect to the original input
        sy : int
            shift in the y-coordinate of image with respect to the original input
        debug : bool
            if True, all subsets, there associated scores and the Shapley values will be displayed
        max_depth : int
            the maximum number of divisions you want to allow before deciding the tolerance is too low.
        
        Returns
        -------
        ls : list of tuples of tuples of ints
            the list of salient regions in I, corrected for their position in the original input 
        &#34;&#34;&#34;
        
        ls = []
        xf = [image.shape[1], image.shape[2]]

        start = (0, 0)
        end = (xf[0], xf[1])

        size = (end[0] - start[0], end[1] - start[1])
        srs = [[(start, size)] for r in range(len(tolerance))]
        finished = [[] for r in range(len(tolerance))]

        k = 0

        while len(srs[0]) &gt; 0 and k &lt; max_depth:
            all_ = [[] for r in range(len(tolerance))]

            for sr in srs[0]:
                s = self.do_all_optim_tol(image, label, sr[0], sr[1], tolerance, debug)

                for r in range(len(tolerance)):
                    if len(srs[r]) &gt; 0:
                        if s[r] == []:
                            coords = np.array([sr[0][0] + sx, sr[0][1] + sy])
                            finished[r].append((coords, sr[1]))
                        else:
                            all_[r] += s[r]

            for r in range(len(tolerance)):
                srs[r] = all_[r]

            k += 1

        for r in range(len(tolerance)):
            if len(srs[r]) == 0:
                ls.extend(finished[r])
            else:
                print(&#34;Max depth of %d reached at tolerance %.3f&#34; % (max_depth, tolerance[r]))

        return ls

    def saliency_map_optim_all(self, image, label, tolerance, debug=False, max_depth=30, filename=None):
        &#34;&#34;&#34; Create and then show a saliency map built with the Hierarchical Shapley method
        (optimized for using several cropped version of the initial input and several tolerance thresholds).
        
        Parameters
        ----------
        im : torch tensor 
            the input image
        label : int in {0,1}
            the label with respect to which we want to analyze - typically 1
        tolerance : float or list of floats
            the specified tolerance for a sub-region to be considered salient. A list is expected.
        only_one_run : bool
            when False, several runs are done by also considering 16 cropped versions of the input
        debug : bool
            if True, all subsets, there associated scores and the Shapley values will be displayed
        max_depth : int
            the maximum number of divisions you want to allow before deciding the tolerance is too low.
        filename : string 
            name of the file to save the figure to
        
        Returns
        -------
        mask : numpy array 
            the saliency map 
        &#34;&#34;&#34;
        
        ls = []

        xf = [image.shape[1], image.shape[2]]

        start = (0, 0)
        end = (xf[0], xf[1])
        size = (end[0] - start[0], end[1] - start[1])
        lx, ly = image.shape[1], image.shape[2]
        dx, dy = image.shape[1] // 4, image.shape[2] // 4

        # normal
        a = self.get_list_optim_tol(image, label, tolerance, 0, 0, debug=False, max_depth=30)
        ls.append(a)
        count = np.ones(image.shape)

        # shifted to bottom right
        image_br = self.background.clone()
        image_br[:, :lx - dx, :ly - dy] = image[:, dx:, dy:]
        a = self.get_list_optim_tol(image_br, label, tolerance, dx, dy, debug=False, max_depth=30)
        ls.append(a)
        count[:, dx:, dy:] += np.ones((3, lx - dx, ly - dy))

        # shifted to bottom left
        image_bl = self.background.clone()
        image_bl[:, :lx - dx, dy:] = image[:, dx:, :ly - dy]
        a = self.get_list_optim_tol(image_bl, label, tolerance, dx, -dy, debug=False, max_depth=30)
        ls.append(a)
        count[:, dx:, :ly - dy] += np.ones((3, lx - dx, ly - dy))

        # shifted to top left
        image_tl = self.background.clone()
        image_tl[:, dx:, dy:] = image[:, :lx - dx, :ly - dy]
        a = self.get_list_optim_tol(image_tl, label, tolerance, -dx, -dy, debug=False, max_depth=30)
        ls.append(a)
        count[:, :lx - dx, :ly - dy] += np.ones((3, lx - dx, ly - dy))

        # shifted to top right
        image_tr = self.background.clone()
        image_tr[:, dx:, :ly - dy] = image[:, :lx - dx, dy:]
        a = self.get_list_optim_tol(image_tr, label, tolerance, -dx, dy, debug=False, max_depth=30)
        ls.append(a)
        count[:, :lx - dx, dy:] += np.ones((3, lx - dx, ly - dy))
        
        mask = self.display_salient_optim_rand(image, ls, count, filename)
        return mask</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="Hierarchical Shapley.HierarchicalShapley.HierarchicalShap"><code class="flex name class">
<span>class <span class="ident">HierarchicalShap</span></span>
<span>(</span><span>model, background, mean=array([0.5, 0.5, 0.5]), sd=array([0.5, 0.5, 0.5]))</span>
</code></dt>
<dd>
<div class="desc"><p>Explains the salient regions of images according a given network using a hierarchical method based on Shapley values. </p>
<p>Initialize the explanation model. </p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>model</code></strong> :&ensp;<code>a torch neural network (typically torch.nn.Module</code> or <code>a subclass</code> of <code>it)</code></dt>
<dd>the model whose decisions you wish to study</dd>
<dt><strong><code>background</code></strong> :&ensp;<code>torch tensor </code></dt>
<dd>used to remove the contribution of non-considered regions when constructing subsets</dd>
<dt><strong><code>mean</code></strong> :&ensp;<code>array</code> of <code>shape (3,)</code></dt>
<dd>the mean of each channel in the dataset, used for image normalization (useful for plotting from input)</dd>
<dt><strong><code>sd</code></strong> :&ensp;<code>array</code> of <code>shape (3,)</code></dt>
<dd>the standard deviation of each channel in the dataset, used for normalization (useful for plotting from input)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class HierarchicalShap:
    &#34;&#34;&#34;
    Explains the salient regions of images according a given network using a hierarchical method based on Shapley values. 
    &#34;&#34;&#34;

    def __init__(self, model, background, mean=np.array([0.5, 0.5, 0.5]), sd=np.array([0.5, 0.5, 0.5])):
        &#34;&#34;&#34; Initialize the explanation model. 
        
        Parameters
        ----------
        model : a torch neural network (typically torch.nn.Module or a subclass of it)
            the model whose decisions you wish to study
        background : torch tensor 
            used to remove the contribution of non-considered regions when constructing subsets
        mean : array of shape (3,)
            the mean of each channel in the dataset, used for image normalization (useful for plotting from input)
        sd : array of shape (3,)
            the standard deviation of each channel in the dataset, used for normalization (useful for plotting from input)
        &#34;&#34;&#34;
        
        self.model = model
        self.background = background
        self.mean = mean
        self.sd = sd

    def display_cropped_images(self, images, scores):
        &#34;&#34;&#34; Draw the subsets (images resulting from removing certain quadrants).
        
        Parameters
        ----------
        images : torch tensor
            all the subsets to draw
        scores : numpy array of shape (16,)
            the scores for each input
        &#34;&#34;&#34;
        
        fig, axs = plt.subplots(4, 4, figsize=(15, 15))
        for i in range(4):
            for j in range(4):
                im = images[4 * i + j].numpy().transpose(1, 2, 0)
                im = im * self.sd + self.mean
                axs[i, j].imshow(im)
                axs[i, j].set_title(&#34;#%d score:%f &#34; % (4 * i + j, scores[4 * i + j]))

    def construct_subsets(self, im, s=(0, 0), region_size=(None, None)):
        &#34;&#34;&#34; Construct the subsets of im: all possible image resulting from removing from im the content of 0, 1, 2, 3
        or all 4 quadrants of the region defined by start and region_size.
        
        Parameters
        ----------
        im : torch tensor 
            the input image
        s : tuple of ints
            the top left pixel coordinates of the region analyzed
        region_size : tuple of ints
            the size of the region analyzed
        
        Returns
        --------
        subsets : the list of 16 images
        r_coord : a 2x2 array where each entry is a tuple of tuples; the first indicating the start
                  of the region and the second its size
        &#34;&#34;&#34;

        m = (s[0] + region_size[0] // 2, s[1] + region_size[1] // 2)
        e = (s[0] + region_size[0], s[1] + region_size[1])

        top_left = (s, (m[0] - s[0], m[1] - s[1]))
        top_right = ((s[0], m[1]), (m[0] - s[0], e[1] - m[1]))
        bottom_left = ((m[0], s[1]), (e[0] - m[0], m[1] - s[1]))
        bottom_right = (m, (e[0] - m[0], e[1] - m[1]))
        r_coord = np.array([[top_left, top_right], [bottom_left, bottom_right]])

        subsets_size = [16, im.shape[0], im.shape[1], im.shape[2]]

        bg = self.background
        # removing 0 features
        im1234 = bg.clone()
        im1234[:, s[0]:e[0], s[1]:e[1]] = im[:, s[0]:e[0], s[1]:e[1]]
        # removing 1 feature
        im234 = im1234.clone()
        im234[:, s[0]:m[0], s[1]:m[1]] = bg[:, s[0]:m[0], s[1]:m[1]]
        im134 = im1234.clone()
        im134[:, s[0]:m[0], m[1]:e[1]] = bg[:, s[0]:m[0], m[1]:e[1]]
        im124 = im1234.clone()
        im124[:, m[0]:e[0], s[1]:m[1]] = bg[:, m[0]:e[0], s[1]:m[1]]
        im123 = im1234.clone()
        im123[:, m[0]:e[0], m[1]:e[1]] = bg[:, m[0]:e[0], m[1]:e[1]]
        # removing 2 features
        im34 = im234.clone()
        im34[:, s[0]:m[0], m[1]:e[1]] = bg[:, s[0]:m[0], m[1]:e[1]]
        im24 = im234.clone()
        im24[:, m[0]:e[0], s[1]:m[1]] = bg[:, m[0]:e[0], s[1]:m[1]]
        im23 = im234.clone()
        im23[:, m[0]:e[0], m[1]:e[1]] = bg[:, m[0]:e[0], m[1]:e[1]]
        im14 = im134.clone()
        im14[:, m[0]:e[0], s[1]:m[1]] = bg[:, m[0]:e[0], s[1]:m[1]]
        im13 = im134.clone()
        im13[:, m[0]:e[0], m[1]:e[1]] = bg[:, m[0]:e[0], m[1]:e[1]]
        im12 = im123.clone()
        im12[:, m[0]:e[0], s[1]:m[1]] = bg[:, m[0]:e[0], s[1]:m[1]]
        # removing 3 features
        im4 = im34.clone()
        im4[:, m[0]:e[0], s[1]:m[1]] = bg[:, m[0]:e[0], s[1]:m[1]]
        im3 = im34.clone()
        im3[:, m[0]:e[0], m[1]:e[1]] = bg[:, m[0]:e[0], m[1]:e[1]]
        im2 = im24.clone()
        im2[:, m[0]:e[0], m[1]:e[1]] = bg[:, m[0]:e[0], m[1]:e[1]]
        im1 = im14.clone()
        im1[:, m[0]:e[0], m[1]:e[1]] = bg[:, m[0]:e[0], m[1]:e[1]]
        # removing 4
        im_ = bg.clone()

        subsets = torch.zeros(size=subsets_size)
        subsets[0] = im1234
        subsets[1] = im234
        subsets[2] = im134
        subsets[3] = im124
        subsets[4] = im123
        subsets[5] = im34
        subsets[6] = im24
        subsets[7] = im23
        subsets[8] = im14
        subsets[9] = im13
        subsets[10] = im12
        subsets[11] = im4
        subsets[12] = im3
        subsets[13] = im2
        subsets[14] = im1
        subsets[15] = im_

        return subsets, r_coord

    def subset_scores(self, sub, label):
        &#34;&#34;&#34; Compute the scores of each subset input.
        
        Parameters
        ----------
        sub : the subsets of inputs
        label : the class label - typically 1 -  in which we&#39;re interested.
        
        Returns
        --------
        score : numpy array of shape (16,)
            the scores for each input
        &#34;&#34;&#34;
        
        outputs = self.model(sub)
        score = outputs[:, label].detach().numpy()

        return score

    def shapley_of_quadrants(self, score):
        &#34;&#34;&#34; Compute the Shapley values associated with each quadrant.
        
        Parameters
        ----------
        score : the network evaluation for each subset
        
        Returns
        --------
        shapley_coefficients : array of shape (2,2) 
            the shapley coefficients of each quadrant
        &#34;&#34;&#34;

        phi1 = (score[14] - score[15] + score[0] - score[1]) / 4\
               + (score[8] - score[11] + score[9] - score[12] + score[10] - score[13]
                  + score[2] - score[5] + score[3] - score[6] + score[4] - score[7]) / 12

        phi2 = (score[13] - score[15] + score[0] - score[2]) / 4 \
               + (score[6] - score[11] + score[7] - score[12] + score[10] - score[14]
                  + score[1] - score[5] + score[3] - score[8] + score[4] - score[9]) / 12

        phi3 = (score[12] - score[15] + score[0] - score[3]) / 4 \
               + (score[5] - score[11] + score[9] - score[14] + score[7] - score[13]
                  + score[2] - score[8] + score[1] - score[6] + score[4] - score[10]) / 12

        phi4 = (score[11] - score[15] + score[0] - score[4]) / 4 \
               + (score[8] - score[14] + score[5] - score[12] + score[6] - score[13]
                  + score[1] - score[7] + score[3] - score[10] + score[2] - score[9]) / 12

        shapley_coefficients = np.array([[phi1, phi2], [phi3, phi4]])
        
        return shapley_coefficients

    def get_salient_regions(self, shapley_values, tol, regions):
        &#34;&#34;&#34; Determine which of the 4 quadrants are salient, i.e. have Shapley value larger than tol.
        
        Parameters
        ----------
        shapley_values : array of shape (2,2) 
            the shapley coefficients of each quadrant
        tol : float 
            the specified tolerance for a sub-region to be considered salient
        regions : the coordinates associated with each quadrant
        
        Returns
        --------
        srs : list of tuples of tuples of ints 
            a list of all salient regions (a tuple with start coordinates, size), i.e. regions whose Shapley values were large enough
        &#34;&#34;&#34;
        
        srs = []
        for i in range(len(shapley_values)):
            for j in range(len(shapley_values[0])):
                if shapley_values[i, j] &gt; tol:
                    srs.append(regions[i, j])

        return srs

    def display_salient(self, im, srs_coll, count, filename):
        &#34;&#34;&#34; Determine which of the 4 quadrants are salient, i.e. have Shapley value larger than tol.
        
        Parameters
        ----------
        im : torch tensor 
            the input image
        srs_coll : a collection of all regions deemed salient
        count : numpy array
            a normalizing mask which determines how many time each pixel was given a chance to be counted as salient
        filename : string 
            name of the file to save the figure
        
        Returns
        -------
        mask : numpy array 
            the saliency map 
        &#34;&#34;&#34;
        
        fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(60, 30))

        sample_image = im.numpy().transpose(1, 2, 0)
        count = count.transpose(1, 2, 0)
        ax4.imshow(count / np.max(count))
        image = sample_image * self.sd + self.mean
        ax1.imshow(image)
        ax2.imshow(image)
        mask = np.zeros(image.shape)

        # Count how many time each pixel was found to be in a salient region
        for srs in srs_coll:
            for sr in srs:
                start = sr[0]
                q_size = sr[1]
                xs = [start[1], start[1] + q_size[1], start[1] + q_size[1], start[1]]
                ys = [start[0], start[0], start[0] + q_size[0], start[0] + q_size[0]]
                ax2.fill(xs, ys, &#39;r&#39;, alpha=1 / len(srs_coll))

                mask[start[0]:start[0] + q_size[0], start[1]:start[1] + q_size[1], :] += np.ones(
                    (q_size[0], q_size[1], 3))

        # Normalize the mask by the number of tries in each region
        mask /= count
        # Normalize the mask to the range (0,1)
        mask /= np.max(mask)
        # Set to 0 elements smaller than 1/5
        negligible = (mask &lt; 1 / 5)
        mask[negligible] = 0

        ax1.set_xlim([0, im.shape[2]])
        ax1.set_ylim([im.shape[1], 0])
        ax2.set_xlim([0, im.shape[2]])
        ax2.set_ylim([im.shape[1], 0])
        ax3.imshow(image * mask)
        if filename != None:
            plt.savefig(filename, dpi=300)
        return mask

    def do_all(self, im, label, start, region_size, tol, debug=False):
        &#34;&#34;&#34; Secondary main loop: do everything for one region of the image.
        
        Parameters
        ----------
        im : torch tensor 
            the input image
        start : tuple of ints
            the starting coordinates of the region
        region_size : tuple of ints
            size of the region
        tol : float
            the specified tolerance for a sub-region to be considered salient
        debug : bool 
            if True, all subsets, there associated scores and the Shapley values will be displayed
            
        Returns
        --------
        srs : list of tuples of tuples of ints 
            a list of all salient regions (a tuple with start coordinates, size), i.e. regions whose Shapley values were large enough
        &#34;&#34;&#34;
        
        images_final, regions = self.construct_subsets(im, start, region_size)
        score = self.subset_scores(images_final, label)
        sm = self.shapley_of_quadrants(score)
        if debug:
            self.display_cropped_images(images_final, score)
            f = plt.figure()
            sns.heatmap(sm)
            f.suptitle(&#34;Shap values of each quadrant&#34;)

        srs = self.get_salient_regions(sm, tol, regions)

        return srs

    def saliency_map(self, image, label, tolerance, only_one_run=False, debug=False, max_depth=30, filename=None):
        &#34;&#34;&#34; Create and then show a saliency map built with the Hierarchical Shapley method.
        
        Parameters
        ----------
        image : torch tensor 
            the input image
        label : int in {0,1}
            the label with respect to which we want to analyze - typically 1
        tolerance : float
            the specified tolerance for a sub-region to be considered salient. A list is expected.
        only_one_run : bool
            when False, several runs are done by also considering 16 cropped versions of the input
        debug : bool
            if True, all subsets, there associated scores and the Shapley values will be displayed
        max_depth : int
            the maximum number of divisions you want to allow before deciding the tolerance is too low.
        filename : string
            name of the file to save the figure to
        
        Returns
        -------
        mask : numpy array
            the saliency map 
        &#34;&#34;&#34;
        
        ls = []
        count = np.zeros(image.shape)
        xf = [image.shape[1], image.shape[2]]

        if only_one_run:
            starts = [(0, 0)]
            ends = [(xf[0], xf[1])]
        else:
            delta = [image.shape[1] // 20, image.shape[2] // 24]
            starts = [(0, 0), (0, delta[1]), (delta[0], 0), (delta[0], delta[1])]
            ends = [(xf[0], xf[1]), (xf[0], xf[1] - delta[1]), (xf[0] - delta[0], xf[1]),
                    (xf[0] - delta[0], xf[1] - delta[1])]

        for start in starts:
            for end in ends:
                size = (end[0] - start[0], end[1] - start[1])
                count[:, start[0]:end[0], start[1]:end[1]] += np.ones((3, size[0], size[1]))

        for tol in tolerance:
            try:
                for start in starts:
                    for end in ends:

                        size = (end[0] - start[0], end[1] - start[1])
                        srs = [(start, size)]
                        finished = []
                        k = 0

                        while len(srs) &gt; 0:

                            if k &gt; max_depth:
                                raise RuntimeError(&#34;Depth %d reached at tolerance %f&#34; % (k, tol))
                            all_ = []
                            for sr in srs:
                                s = self.do_all(image, label, sr[0], sr[1], tol, debug)
                                if s == []:
                                    finished.append(((sr[0]), (sr[1])))

                                else:
                                    all_ += s
                            srs = all_
                            k += 1
                        ls.append(finished)
            except RuntimeError as w:
                print(w, &#34;Run ignored, consider increasing tolerance.&#34;)

        mask = self.display_salient(image, ls, count, filename)
        return mask

    def get_salient_regions_optim_tol(self, shapley_values, tols, regions):
        &#34;&#34;&#34; Determine which of the 4 quadrants are salient, i.e. have Shapley value larger than tol.
        
        Parameters
        ----------
        shapley_values : array of shape (2,2)
            the Shapley coefficients associated with each quadrant
        tol : float
            the specified tolerance for a sub-region to be considered salient
        regions : the coordinates associated with each quadrant
        
        Returns
        --------
        srs : list of tuples of tuples of ints 
            a list of all salient regions (a tuple with start coordinates, size), i.e. regions whose Shapley values were large enough
        &#34;&#34;&#34;
        
        srs = [[] for r in range(len(tols))]
        for i in range(len(shapley_values)):
            for j in range(len(shapley_values[0])):
                for r in range(len(tols)):
                    if shapley_values[i, j] &gt; tols[r]:
                        srs[r].append(regions[i, j])
        return srs

    def do_all_optim_tol(self, im, label, start, region_size, tols, debug=False):
        &#34;&#34;&#34; Secondary main loop: do everything for one region of the image, in a way that is optimal when using several tolerances 
        
        Parameters
        ----------
        im : torch tensor 
            the input image
        start : tuple of ints
            the starting coordinates of the region
        region_size : tuple of ints
            size of the region
        tol : float or list of flaots
            the specified tolerance for a sub-region to be considered salient
        debug : bool
            if True, all subsets, there associated scores and the Shapley values will be displayed
            
        Returns
        --------
        srs : list of tuples of tuples of ints 
            a list of all salient regions (a tuple with start coordinates, size), i.e. regions whose Shapley values were large enough
        &#34;&#34;&#34;
        
        images_final, regions = self.construct_subsets(im, start, region_size)
        score = self.subset_scores(images_final, label)
        sm = self.shapley_of_quadrants(score)
        if debug:
            self.display_cropped_images(images_final, score)
            f = plt.figure()
            sns.heatmap(sm)
            f.suptitle(&#34;Shap values of each quadrant&#34;)

        srs = self.get_salient_regions_optim_tol(sm, tols, regions)

        return srs

    def saliency_map_optim_tol(self, image, label, tolerance, only_one_run=False, debug=False, max_depth=30,
                               filename=None):
        &#34;&#34;&#34; Create and then show a saliency map built with the Hierarchical Shapley method (optimized for when using a list of tolerances).
        
        Parameters
        ----------
        im : torch tensor 
            the input image
        label : int in {0,1}
            the label with respect to which we want to analyze - typically 1
        tolerance : float or list of floats
            the specified tolerance for a sub-region to be considered salient. A list is expected.
        only_one_run : bool 
            when False, several runs are done by also considering 16 cropped versions of the input
        debug : bool, optional 
            if True, all subsets, there associated scores and the Shapley values will be displayed
        max_depth : int, optional 
            the maximum number of divisions you want to allow before deciding the tolerance is too low.
        filename : string, optional 
            name of the file to save the figure to
        
        Returns
        -------
        mask : numpy array
            the saliency map 
        &#34;&#34;&#34;
        
        ls = []
        count = np.zeros(image.shape)
        xf = [image.shape[1], image.shape[2]]

        if only_one_run:
            starts = [(0, 0)]
            ends = [(xf[0], xf[1])]
        else:
            delta = [image.shape[1] // 20, image.shape[2] // 24]
            starts = [(0, 0), (0, delta[1]), (delta[0], 0), (delta[0], delta[1])]
            ends = [(xf[0], xf[1]), (xf[0], xf[1] - delta[1]), (xf[0] - delta[0], xf[1]),
                    (xf[0] - delta[0], xf[1] - delta[1])]

        for start in starts:
            for end in ends:
                size = (end[0] - start[0], end[1] - start[1])
                count[:, start[0]:end[0], start[1]:end[1]] += np.ones((3, size[0], size[1]))

        for start in starts:
            for end in ends:

                size = (end[0] - start[0], end[1] - start[1])
                srs = [[(start, size)] for r in range(len(tolerance))]
                finished = [[] for r in range(len(tolerance))]
                was_finished = [True for r in range(len(tolerance))]
                k = 0

                while len(srs[0]) &gt; 0 and k &lt; max_depth:
                    all_ = [[] for r in range(len(tolerance))]

                    for sr in srs[0]:
                        s = self.do_all_optim_tol(image, label, sr[0], sr[1], tolerance, debug)

                        for r in range(len(tolerance)):
                            if len(srs[r]) &gt; 0:
                                if s[r] == []:
                                    finished[r].append(((sr[0]), (sr[1])))
                                else:
                                    all_[r] += s[r]

                    for r in range(len(tolerance)):
                        srs[r] = all_[r]

                    k += 1

                for r in range(len(tolerance)):
                    if len(srs[r]) == 0:
                        ls.append(finished[r])
                    else:
                        print(&#34;Max depth of %d reached at tolerance %.3f&#34; % (max_depth, tolerance[r]))

        mask = self.display_salient(image, ls, count, filename)
        return mask
    
    def saliency_map_optim_rand(self, image, label, tolerance, debug=False, max_depth=30, filename=None):
        &#34;&#34;&#34; Create and then show a saliency map built with the Hierarchical Shapley method 
        (optimized for using several cropped versions of the original input). 
        
        Parameters
        ----------
        im : torch tensor 
            the input image
        label : int in {0,1}
            the label with respect to which we want to analyze - typically 1
        tolerance : float or list of floats
            the tolerance for a sub-region to be considered salient. A list is expected.
        only_one_run : bool 
            when False, several runs are done by also considering 16 cropped versions of the input
        debug : bool 
            if True, all subsets, there associated scores and the Shapley values will be displayed
        max_depth : int
            the maximum number of divisions you want to allow before deciding the tolerance is too low.
        filename : string 
            name of the file to save the figure to
            
        Returns
        -------
        mask : numpy array
            the saliency map 
        &#34;&#34;&#34;
        
        ls = []

        xf = [image.shape[1], image.shape[2]]

        start = (0, 0)
        end = (xf[0], xf[1])
        size = (end[0] - start[0], end[1] - start[1])
        lx, ly = image.shape[1], image.shape[2]
        dx, dy = image.shape[1] // 4, image.shape[2] // 4

        def salient_regions(I, sx, sy):
            &#34;&#34;&#34; Get salient regions of image I, knowing that it has been shifted by sx and sy from the original input. &#34;&#34;&#34;
            
            finished = []

            for tol in tolerance:
                k = 0
                srs = [(start, size)]
                current = []
                while len(srs) &gt; 0 and k &lt; max_depth:
                    all_ = []
                    for sr in srs:
                        s = self.do_all(I, label, sr[0], sr[1], tol, debug)
                        if s == []:
                            coords = np.array([sr[0][0] + sx, sr[0][1] + sy])
                            current.append((coords, sr[1]))
                        else:
                            all_ += s
                    srs = all_
                    k += 1
                if (k &lt; max_depth):
                    finished += current
            return finished

        # normal
        a = salient_regions(image, 0, 0)
        ls.append(a)
        count = np.ones(image.shape)

        # shifted to bottom right
        image_br = self.background.clone()
        image_br[:, :lx - dx, :ly - dy] = image[:, dx:, dy:]
        ls.append(salient_regions(image_br, dx, dy))
        count[:, dx:, dy:] += np.ones((3, lx - dx, ly - dy))

        # shifted to bottom left
        image_bl = self.background.clone()
        image_bl[:, :lx - dx, dy:] = image[:, dx:, :ly - dy]
        ls.append(salient_regions(image_bl, dx, -dy))
        count[:, dx:, :ly - dy] += np.ones((3, lx - dx, ly - dy))

        # shifted to top left
        image_tl = self.background.clone()
        image_tl[:, dx:, dy:] = image[:, :lx - dx, :ly - dy]
        ls.append(salient_regions(image_tl, -dx, -dy))
        count[:, :lx - dx, :ly - dy] += np.ones((3, lx - dx, ly - dy))

        # shifted to top right
        image_tr = self.background.clone()
        image_tr[:, dx:, :ly - dy] = image[:, :lx - dx, dy:]
        ls.append(salient_regions(image_tr, -dx, dy))
        count[:, :lx - dx, dy:] += np.ones((3, lx - dx, ly - dy))

        mask = self.display_salient_optim_rand(image, ls, count, filename)
        return mask

    def display_salient_optim_rand(self, im, srs_coll, count, filename):
        &#34;&#34;&#34; Determine which of the 4 quadrants are salient, i.e. have Shapley value larger than tol
        (optimized for using several cropped versions of the original input). 
        
        Parameters
        ----------
        im : torch tensor 
            the input image
        srs_coll : a collection of all regions deemed salient
        count : numpy array
            a normalizing mask which determines how many time each pixel was given a chance to be salient
        filename : string 
            name of the file to save the figure to
        
        Returns
        -------
        mask : numpy array
            the saliency map 
        &#34;&#34;&#34;
        
        fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(60, 30))

        sample_image = im.numpy().transpose(1, 2, 0)
        count = count.transpose(1, 2, 0)
        ax4.imshow(count / np.max(count))
        image = sample_image * self.sd + self.mean
        ax1.imshow(image)
        ax2.imshow(image)
        mask = np.zeros(image.shape)

        # Count how many time each pixel was found to be in a salient region
        for srs in srs_coll:
            for sr in srs:
                start = sr[0]
                q_size = sr[1]

                if (start[0] &gt;= 0 and start[0] + q_size[0] &lt;= image.shape[0] and start[1] &gt;= 0 and start[1] + q_size[
                    1] &lt;= image.shape[1]):
                    xs = [start[1], start[1] + q_size[1], start[1] + q_size[1], start[1]]
                    ys = [start[0], start[0], start[0] + q_size[0], start[0] + q_size[0]]
                    ax2.fill(xs, ys, &#39;r&#39;, alpha=1 / len(srs_coll))

                    mask[start[0]:start[0] + q_size[0], start[1]:start[1] + q_size[1], :] += np.ones(
                        (q_size[0], q_size[1], 3))

        # Normalize the mask by the number of tries in each region
        mask /= count
        # Normalize the mask to the range (0,1)
        mask /= np.max(mask)
        # Set to 0 elements smaller than 1/5
        negligible = (mask &lt; 1 / 5)
        mask[negligible] = 0

        ax1.set_xlim([0, im.shape[2]])
        ax1.set_ylim([im.shape[1], 0])
        ax2.set_xlim([0, im.shape[2]])
        ax2.set_ylim([im.shape[1], 0])
        ax3.imshow(image * mask)
        if filename != None:
            plt.savefig(filename, dpi=300)
        return mask

    def get_list_optim_tol(self, image, label, tolerance, sx, sy, debug=False, max_depth=30):
        &#34;&#34;&#34; Create and then show a saliency map built with the Hierarchical Shapley method
        (optimized for using several cropped version of the initial input and several tolerance thresholds).
        
        Parameters
        ----------
        image : torch tensor 
            the input image
        label : int in {0,1}
            the label with respect to which we want to analyze - typically 1
        tolerance : float or list of floats
            the specified tolerance for a sub-region to be considered salient. A list is expected.
        sx : int
            shift in the x-coordinate of image with respect to the original input
        sy : int
            shift in the y-coordinate of image with respect to the original input
        debug : bool
            if True, all subsets, there associated scores and the Shapley values will be displayed
        max_depth : int
            the maximum number of divisions you want to allow before deciding the tolerance is too low.
        
        Returns
        -------
        ls : list of tuples of tuples of ints
            the list of salient regions in I, corrected for their position in the original input 
        &#34;&#34;&#34;
        
        ls = []
        xf = [image.shape[1], image.shape[2]]

        start = (0, 0)
        end = (xf[0], xf[1])

        size = (end[0] - start[0], end[1] - start[1])
        srs = [[(start, size)] for r in range(len(tolerance))]
        finished = [[] for r in range(len(tolerance))]

        k = 0

        while len(srs[0]) &gt; 0 and k &lt; max_depth:
            all_ = [[] for r in range(len(tolerance))]

            for sr in srs[0]:
                s = self.do_all_optim_tol(image, label, sr[0], sr[1], tolerance, debug)

                for r in range(len(tolerance)):
                    if len(srs[r]) &gt; 0:
                        if s[r] == []:
                            coords = np.array([sr[0][0] + sx, sr[0][1] + sy])
                            finished[r].append((coords, sr[1]))
                        else:
                            all_[r] += s[r]

            for r in range(len(tolerance)):
                srs[r] = all_[r]

            k += 1

        for r in range(len(tolerance)):
            if len(srs[r]) == 0:
                ls.extend(finished[r])
            else:
                print(&#34;Max depth of %d reached at tolerance %.3f&#34; % (max_depth, tolerance[r]))

        return ls

    def saliency_map_optim_all(self, image, label, tolerance, debug=False, max_depth=30, filename=None):
        &#34;&#34;&#34; Create and then show a saliency map built with the Hierarchical Shapley method
        (optimized for using several cropped version of the initial input and several tolerance thresholds).
        
        Parameters
        ----------
        im : torch tensor 
            the input image
        label : int in {0,1}
            the label with respect to which we want to analyze - typically 1
        tolerance : float or list of floats
            the specified tolerance for a sub-region to be considered salient. A list is expected.
        only_one_run : bool
            when False, several runs are done by also considering 16 cropped versions of the input
        debug : bool
            if True, all subsets, there associated scores and the Shapley values will be displayed
        max_depth : int
            the maximum number of divisions you want to allow before deciding the tolerance is too low.
        filename : string 
            name of the file to save the figure to
        
        Returns
        -------
        mask : numpy array 
            the saliency map 
        &#34;&#34;&#34;
        
        ls = []

        xf = [image.shape[1], image.shape[2]]

        start = (0, 0)
        end = (xf[0], xf[1])
        size = (end[0] - start[0], end[1] - start[1])
        lx, ly = image.shape[1], image.shape[2]
        dx, dy = image.shape[1] // 4, image.shape[2] // 4

        # normal
        a = self.get_list_optim_tol(image, label, tolerance, 0, 0, debug=False, max_depth=30)
        ls.append(a)
        count = np.ones(image.shape)

        # shifted to bottom right
        image_br = self.background.clone()
        image_br[:, :lx - dx, :ly - dy] = image[:, dx:, dy:]
        a = self.get_list_optim_tol(image_br, label, tolerance, dx, dy, debug=False, max_depth=30)
        ls.append(a)
        count[:, dx:, dy:] += np.ones((3, lx - dx, ly - dy))

        # shifted to bottom left
        image_bl = self.background.clone()
        image_bl[:, :lx - dx, dy:] = image[:, dx:, :ly - dy]
        a = self.get_list_optim_tol(image_bl, label, tolerance, dx, -dy, debug=False, max_depth=30)
        ls.append(a)
        count[:, dx:, :ly - dy] += np.ones((3, lx - dx, ly - dy))

        # shifted to top left
        image_tl = self.background.clone()
        image_tl[:, dx:, dy:] = image[:, :lx - dx, :ly - dy]
        a = self.get_list_optim_tol(image_tl, label, tolerance, -dx, -dy, debug=False, max_depth=30)
        ls.append(a)
        count[:, :lx - dx, :ly - dy] += np.ones((3, lx - dx, ly - dy))

        # shifted to top right
        image_tr = self.background.clone()
        image_tr[:, dx:, :ly - dy] = image[:, :lx - dx, dy:]
        a = self.get_list_optim_tol(image_tr, label, tolerance, -dx, dy, debug=False, max_depth=30)
        ls.append(a)
        count[:, :lx - dx, dy:] += np.ones((3, lx - dx, ly - dy))
        
        mask = self.display_salient_optim_rand(image, ls, count, filename)
        return mask</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="Hierarchical Shapley.HierarchicalShapley.HierarchicalShap.construct_subsets"><code class="name flex">
<span>def <span class="ident">construct_subsets</span></span>(<span>self, im, s=(0, 0), region_size=(None, None))</span>
</code></dt>
<dd>
<div class="desc"><p>Construct the subsets of im: all possible image resulting from removing from im the content of 0, 1, 2, 3
or all 4 quadrants of the region defined by start and region_size.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>im</code></strong> :&ensp;<code>torch tensor </code></dt>
<dd>the input image</dd>
<dt><strong><code>s</code></strong> :&ensp;<code>tuple</code> of <code>ints</code></dt>
<dd>the top left pixel coordinates of the region analyzed</dd>
<dt><strong><code>region_size</code></strong> :&ensp;<code>tuple</code> of <code>ints</code></dt>
<dd>the size of the region analyzed</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>subsets</code></strong> :&ensp;<code>the list</code> of <code>16 images</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>r_coord</code></strong> :&ensp;<code>a 2x2 array where each entry is a tuple</code> of <code>tuples; the first indicating the start</code></dt>
<dd>of the region and the second its size</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def construct_subsets(self, im, s=(0, 0), region_size=(None, None)):
    &#34;&#34;&#34; Construct the subsets of im: all possible image resulting from removing from im the content of 0, 1, 2, 3
    or all 4 quadrants of the region defined by start and region_size.
    
    Parameters
    ----------
    im : torch tensor 
        the input image
    s : tuple of ints
        the top left pixel coordinates of the region analyzed
    region_size : tuple of ints
        the size of the region analyzed
    
    Returns
    --------
    subsets : the list of 16 images
    r_coord : a 2x2 array where each entry is a tuple of tuples; the first indicating the start
              of the region and the second its size
    &#34;&#34;&#34;

    m = (s[0] + region_size[0] // 2, s[1] + region_size[1] // 2)
    e = (s[0] + region_size[0], s[1] + region_size[1])

    top_left = (s, (m[0] - s[0], m[1] - s[1]))
    top_right = ((s[0], m[1]), (m[0] - s[0], e[1] - m[1]))
    bottom_left = ((m[0], s[1]), (e[0] - m[0], m[1] - s[1]))
    bottom_right = (m, (e[0] - m[0], e[1] - m[1]))
    r_coord = np.array([[top_left, top_right], [bottom_left, bottom_right]])

    subsets_size = [16, im.shape[0], im.shape[1], im.shape[2]]

    bg = self.background
    # removing 0 features
    im1234 = bg.clone()
    im1234[:, s[0]:e[0], s[1]:e[1]] = im[:, s[0]:e[0], s[1]:e[1]]
    # removing 1 feature
    im234 = im1234.clone()
    im234[:, s[0]:m[0], s[1]:m[1]] = bg[:, s[0]:m[0], s[1]:m[1]]
    im134 = im1234.clone()
    im134[:, s[0]:m[0], m[1]:e[1]] = bg[:, s[0]:m[0], m[1]:e[1]]
    im124 = im1234.clone()
    im124[:, m[0]:e[0], s[1]:m[1]] = bg[:, m[0]:e[0], s[1]:m[1]]
    im123 = im1234.clone()
    im123[:, m[0]:e[0], m[1]:e[1]] = bg[:, m[0]:e[0], m[1]:e[1]]
    # removing 2 features
    im34 = im234.clone()
    im34[:, s[0]:m[0], m[1]:e[1]] = bg[:, s[0]:m[0], m[1]:e[1]]
    im24 = im234.clone()
    im24[:, m[0]:e[0], s[1]:m[1]] = bg[:, m[0]:e[0], s[1]:m[1]]
    im23 = im234.clone()
    im23[:, m[0]:e[0], m[1]:e[1]] = bg[:, m[0]:e[0], m[1]:e[1]]
    im14 = im134.clone()
    im14[:, m[0]:e[0], s[1]:m[1]] = bg[:, m[0]:e[0], s[1]:m[1]]
    im13 = im134.clone()
    im13[:, m[0]:e[0], m[1]:e[1]] = bg[:, m[0]:e[0], m[1]:e[1]]
    im12 = im123.clone()
    im12[:, m[0]:e[0], s[1]:m[1]] = bg[:, m[0]:e[0], s[1]:m[1]]
    # removing 3 features
    im4 = im34.clone()
    im4[:, m[0]:e[0], s[1]:m[1]] = bg[:, m[0]:e[0], s[1]:m[1]]
    im3 = im34.clone()
    im3[:, m[0]:e[0], m[1]:e[1]] = bg[:, m[0]:e[0], m[1]:e[1]]
    im2 = im24.clone()
    im2[:, m[0]:e[0], m[1]:e[1]] = bg[:, m[0]:e[0], m[1]:e[1]]
    im1 = im14.clone()
    im1[:, m[0]:e[0], m[1]:e[1]] = bg[:, m[0]:e[0], m[1]:e[1]]
    # removing 4
    im_ = bg.clone()

    subsets = torch.zeros(size=subsets_size)
    subsets[0] = im1234
    subsets[1] = im234
    subsets[2] = im134
    subsets[3] = im124
    subsets[4] = im123
    subsets[5] = im34
    subsets[6] = im24
    subsets[7] = im23
    subsets[8] = im14
    subsets[9] = im13
    subsets[10] = im12
    subsets[11] = im4
    subsets[12] = im3
    subsets[13] = im2
    subsets[14] = im1
    subsets[15] = im_

    return subsets, r_coord</code></pre>
</details>
</dd>
<dt id="Hierarchical Shapley.HierarchicalShapley.HierarchicalShap.display_cropped_images"><code class="name flex">
<span>def <span class="ident">display_cropped_images</span></span>(<span>self, images, scores)</span>
</code></dt>
<dd>
<div class="desc"><p>Draw the subsets (images resulting from removing certain quadrants).</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>images</code></strong> :&ensp;<code>torch tensor</code></dt>
<dd>all the subsets to draw</dd>
<dt><strong><code>scores</code></strong> :&ensp;<code>numpy array</code> of <code>shape (16,)</code></dt>
<dd>the scores for each input</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def display_cropped_images(self, images, scores):
    &#34;&#34;&#34; Draw the subsets (images resulting from removing certain quadrants).
    
    Parameters
    ----------
    images : torch tensor
        all the subsets to draw
    scores : numpy array of shape (16,)
        the scores for each input
    &#34;&#34;&#34;
    
    fig, axs = plt.subplots(4, 4, figsize=(15, 15))
    for i in range(4):
        for j in range(4):
            im = images[4 * i + j].numpy().transpose(1, 2, 0)
            im = im * self.sd + self.mean
            axs[i, j].imshow(im)
            axs[i, j].set_title(&#34;#%d score:%f &#34; % (4 * i + j, scores[4 * i + j]))</code></pre>
</details>
</dd>
<dt id="Hierarchical Shapley.HierarchicalShapley.HierarchicalShap.display_salient"><code class="name flex">
<span>def <span class="ident">display_salient</span></span>(<span>self, im, srs_coll, count, filename)</span>
</code></dt>
<dd>
<div class="desc"><p>Determine which of the 4 quadrants are salient, i.e. have Shapley value larger than tol.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>im</code></strong> :&ensp;<code>torch tensor </code></dt>
<dd>the input image</dd>
<dt><strong><code>srs_coll</code></strong> :&ensp;<code>a collection</code> of <code>all regions deemed salient</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>count</code></strong> :&ensp;<code>numpy array</code></dt>
<dd>a normalizing mask which determines how many time each pixel was given a chance to be counted as salient</dd>
<dt><strong><code>filename</code></strong> :&ensp;<code>string </code></dt>
<dd>name of the file to save the figure</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>mask</code></strong> :&ensp;<code>numpy array </code></dt>
<dd>the saliency map</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def display_salient(self, im, srs_coll, count, filename):
    &#34;&#34;&#34; Determine which of the 4 quadrants are salient, i.e. have Shapley value larger than tol.
    
    Parameters
    ----------
    im : torch tensor 
        the input image
    srs_coll : a collection of all regions deemed salient
    count : numpy array
        a normalizing mask which determines how many time each pixel was given a chance to be counted as salient
    filename : string 
        name of the file to save the figure
    
    Returns
    -------
    mask : numpy array 
        the saliency map 
    &#34;&#34;&#34;
    
    fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(60, 30))

    sample_image = im.numpy().transpose(1, 2, 0)
    count = count.transpose(1, 2, 0)
    ax4.imshow(count / np.max(count))
    image = sample_image * self.sd + self.mean
    ax1.imshow(image)
    ax2.imshow(image)
    mask = np.zeros(image.shape)

    # Count how many time each pixel was found to be in a salient region
    for srs in srs_coll:
        for sr in srs:
            start = sr[0]
            q_size = sr[1]
            xs = [start[1], start[1] + q_size[1], start[1] + q_size[1], start[1]]
            ys = [start[0], start[0], start[0] + q_size[0], start[0] + q_size[0]]
            ax2.fill(xs, ys, &#39;r&#39;, alpha=1 / len(srs_coll))

            mask[start[0]:start[0] + q_size[0], start[1]:start[1] + q_size[1], :] += np.ones(
                (q_size[0], q_size[1], 3))

    # Normalize the mask by the number of tries in each region
    mask /= count
    # Normalize the mask to the range (0,1)
    mask /= np.max(mask)
    # Set to 0 elements smaller than 1/5
    negligible = (mask &lt; 1 / 5)
    mask[negligible] = 0

    ax1.set_xlim([0, im.shape[2]])
    ax1.set_ylim([im.shape[1], 0])
    ax2.set_xlim([0, im.shape[2]])
    ax2.set_ylim([im.shape[1], 0])
    ax3.imshow(image * mask)
    if filename != None:
        plt.savefig(filename, dpi=300)
    return mask</code></pre>
</details>
</dd>
<dt id="Hierarchical Shapley.HierarchicalShapley.HierarchicalShap.display_salient_optim_rand"><code class="name flex">
<span>def <span class="ident">display_salient_optim_rand</span></span>(<span>self, im, srs_coll, count, filename)</span>
</code></dt>
<dd>
<div class="desc"><p>Determine which of the 4 quadrants are salient, i.e. have Shapley value larger than tol
(optimized for using several cropped versions of the original input). </p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>im</code></strong> :&ensp;<code>torch tensor </code></dt>
<dd>the input image</dd>
<dt><strong><code>srs_coll</code></strong> :&ensp;<code>a collection</code> of <code>all regions deemed salient</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>count</code></strong> :&ensp;<code>numpy array</code></dt>
<dd>a normalizing mask which determines how many time each pixel was given a chance to be salient</dd>
<dt><strong><code>filename</code></strong> :&ensp;<code>string </code></dt>
<dd>name of the file to save the figure to</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>mask</code></strong> :&ensp;<code>numpy array</code></dt>
<dd>the saliency map</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def display_salient_optim_rand(self, im, srs_coll, count, filename):
    &#34;&#34;&#34; Determine which of the 4 quadrants are salient, i.e. have Shapley value larger than tol
    (optimized for using several cropped versions of the original input). 
    
    Parameters
    ----------
    im : torch tensor 
        the input image
    srs_coll : a collection of all regions deemed salient
    count : numpy array
        a normalizing mask which determines how many time each pixel was given a chance to be salient
    filename : string 
        name of the file to save the figure to
    
    Returns
    -------
    mask : numpy array
        the saliency map 
    &#34;&#34;&#34;
    
    fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(60, 30))

    sample_image = im.numpy().transpose(1, 2, 0)
    count = count.transpose(1, 2, 0)
    ax4.imshow(count / np.max(count))
    image = sample_image * self.sd + self.mean
    ax1.imshow(image)
    ax2.imshow(image)
    mask = np.zeros(image.shape)

    # Count how many time each pixel was found to be in a salient region
    for srs in srs_coll:
        for sr in srs:
            start = sr[0]
            q_size = sr[1]

            if (start[0] &gt;= 0 and start[0] + q_size[0] &lt;= image.shape[0] and start[1] &gt;= 0 and start[1] + q_size[
                1] &lt;= image.shape[1]):
                xs = [start[1], start[1] + q_size[1], start[1] + q_size[1], start[1]]
                ys = [start[0], start[0], start[0] + q_size[0], start[0] + q_size[0]]
                ax2.fill(xs, ys, &#39;r&#39;, alpha=1 / len(srs_coll))

                mask[start[0]:start[0] + q_size[0], start[1]:start[1] + q_size[1], :] += np.ones(
                    (q_size[0], q_size[1], 3))

    # Normalize the mask by the number of tries in each region
    mask /= count
    # Normalize the mask to the range (0,1)
    mask /= np.max(mask)
    # Set to 0 elements smaller than 1/5
    negligible = (mask &lt; 1 / 5)
    mask[negligible] = 0

    ax1.set_xlim([0, im.shape[2]])
    ax1.set_ylim([im.shape[1], 0])
    ax2.set_xlim([0, im.shape[2]])
    ax2.set_ylim([im.shape[1], 0])
    ax3.imshow(image * mask)
    if filename != None:
        plt.savefig(filename, dpi=300)
    return mask</code></pre>
</details>
</dd>
<dt id="Hierarchical Shapley.HierarchicalShapley.HierarchicalShap.do_all"><code class="name flex">
<span>def <span class="ident">do_all</span></span>(<span>self, im, label, start, region_size, tol, debug=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Secondary main loop: do everything for one region of the image.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>im</code></strong> :&ensp;<code>torch tensor </code></dt>
<dd>the input image</dd>
<dt><strong><code>start</code></strong> :&ensp;<code>tuple</code> of <code>ints</code></dt>
<dd>the starting coordinates of the region</dd>
<dt><strong><code>region_size</code></strong> :&ensp;<code>tuple</code> of <code>ints</code></dt>
<dd>size of the region</dd>
<dt><strong><code>tol</code></strong> :&ensp;<code>float</code></dt>
<dd>the specified tolerance for a sub-region to be considered salient</dd>
<dt><strong><code>debug</code></strong> :&ensp;<code>bool </code></dt>
<dd>if True, all subsets, there associated scores and the Shapley values will be displayed</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>srs</code></strong> :&ensp;<code>list</code> of <code>tuples</code> of <code>tuples</code> of <code>ints </code></dt>
<dd>a list of all salient regions (a tuple with start coordinates, size), i.e. regions whose Shapley values were large enough</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def do_all(self, im, label, start, region_size, tol, debug=False):
    &#34;&#34;&#34; Secondary main loop: do everything for one region of the image.
    
    Parameters
    ----------
    im : torch tensor 
        the input image
    start : tuple of ints
        the starting coordinates of the region
    region_size : tuple of ints
        size of the region
    tol : float
        the specified tolerance for a sub-region to be considered salient
    debug : bool 
        if True, all subsets, there associated scores and the Shapley values will be displayed
        
    Returns
    --------
    srs : list of tuples of tuples of ints 
        a list of all salient regions (a tuple with start coordinates, size), i.e. regions whose Shapley values were large enough
    &#34;&#34;&#34;
    
    images_final, regions = self.construct_subsets(im, start, region_size)
    score = self.subset_scores(images_final, label)
    sm = self.shapley_of_quadrants(score)
    if debug:
        self.display_cropped_images(images_final, score)
        f = plt.figure()
        sns.heatmap(sm)
        f.suptitle(&#34;Shap values of each quadrant&#34;)

    srs = self.get_salient_regions(sm, tol, regions)

    return srs</code></pre>
</details>
</dd>
<dt id="Hierarchical Shapley.HierarchicalShapley.HierarchicalShap.do_all_optim_tol"><code class="name flex">
<span>def <span class="ident">do_all_optim_tol</span></span>(<span>self, im, label, start, region_size, tols, debug=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Secondary main loop: do everything for one region of the image, in a way that is optimal when using several tolerances </p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>im</code></strong> :&ensp;<code>torch tensor </code></dt>
<dd>the input image</dd>
<dt><strong><code>start</code></strong> :&ensp;<code>tuple</code> of <code>ints</code></dt>
<dd>the starting coordinates of the region</dd>
<dt><strong><code>region_size</code></strong> :&ensp;<code>tuple</code> of <code>ints</code></dt>
<dd>size of the region</dd>
<dt><strong><code>tol</code></strong> :&ensp;<code>float</code> or <code>list</code> of <code>flaots</code></dt>
<dd>the specified tolerance for a sub-region to be considered salient</dd>
<dt><strong><code>debug</code></strong> :&ensp;<code>bool</code></dt>
<dd>if True, all subsets, there associated scores and the Shapley values will be displayed</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>srs</code></strong> :&ensp;<code>list</code> of <code>tuples</code> of <code>tuples</code> of <code>ints </code></dt>
<dd>a list of all salient regions (a tuple with start coordinates, size), i.e. regions whose Shapley values were large enough</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def do_all_optim_tol(self, im, label, start, region_size, tols, debug=False):
    &#34;&#34;&#34; Secondary main loop: do everything for one region of the image, in a way that is optimal when using several tolerances 
    
    Parameters
    ----------
    im : torch tensor 
        the input image
    start : tuple of ints
        the starting coordinates of the region
    region_size : tuple of ints
        size of the region
    tol : float or list of flaots
        the specified tolerance for a sub-region to be considered salient
    debug : bool
        if True, all subsets, there associated scores and the Shapley values will be displayed
        
    Returns
    --------
    srs : list of tuples of tuples of ints 
        a list of all salient regions (a tuple with start coordinates, size), i.e. regions whose Shapley values were large enough
    &#34;&#34;&#34;
    
    images_final, regions = self.construct_subsets(im, start, region_size)
    score = self.subset_scores(images_final, label)
    sm = self.shapley_of_quadrants(score)
    if debug:
        self.display_cropped_images(images_final, score)
        f = plt.figure()
        sns.heatmap(sm)
        f.suptitle(&#34;Shap values of each quadrant&#34;)

    srs = self.get_salient_regions_optim_tol(sm, tols, regions)

    return srs</code></pre>
</details>
</dd>
<dt id="Hierarchical Shapley.HierarchicalShapley.HierarchicalShap.get_list_optim_tol"><code class="name flex">
<span>def <span class="ident">get_list_optim_tol</span></span>(<span>self, image, label, tolerance, sx, sy, debug=False, max_depth=30)</span>
</code></dt>
<dd>
<div class="desc"><p>Create and then show a saliency map built with the Hierarchical Shapley method
(optimized for using several cropped version of the initial input and several tolerance thresholds).</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>image</code></strong> :&ensp;<code>torch tensor </code></dt>
<dd>the input image</dd>
<dt><strong><code>label</code></strong> :&ensp;<code>int in {0,1}</code></dt>
<dd>the label with respect to which we want to analyze - typically 1</dd>
<dt><strong><code>tolerance</code></strong> :&ensp;<code>float</code> or <code>list</code> of <code>floats</code></dt>
<dd>the specified tolerance for a sub-region to be considered salient. A list is expected.</dd>
<dt><strong><code>sx</code></strong> :&ensp;<code>int</code></dt>
<dd>shift in the x-coordinate of image with respect to the original input</dd>
<dt><strong><code>sy</code></strong> :&ensp;<code>int</code></dt>
<dd>shift in the y-coordinate of image with respect to the original input</dd>
<dt><strong><code>debug</code></strong> :&ensp;<code>bool</code></dt>
<dd>if True, all subsets, there associated scores and the Shapley values will be displayed</dd>
<dt><strong><code>max_depth</code></strong> :&ensp;<code>int</code></dt>
<dd>the maximum number of divisions you want to allow before deciding the tolerance is too low.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>ls</code></strong> :&ensp;<code>list</code> of <code>tuples</code> of <code>tuples</code> of <code>ints</code></dt>
<dd>the list of salient regions in I, corrected for their position in the original input</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_list_optim_tol(self, image, label, tolerance, sx, sy, debug=False, max_depth=30):
    &#34;&#34;&#34; Create and then show a saliency map built with the Hierarchical Shapley method
    (optimized for using several cropped version of the initial input and several tolerance thresholds).
    
    Parameters
    ----------
    image : torch tensor 
        the input image
    label : int in {0,1}
        the label with respect to which we want to analyze - typically 1
    tolerance : float or list of floats
        the specified tolerance for a sub-region to be considered salient. A list is expected.
    sx : int
        shift in the x-coordinate of image with respect to the original input
    sy : int
        shift in the y-coordinate of image with respect to the original input
    debug : bool
        if True, all subsets, there associated scores and the Shapley values will be displayed
    max_depth : int
        the maximum number of divisions you want to allow before deciding the tolerance is too low.
    
    Returns
    -------
    ls : list of tuples of tuples of ints
        the list of salient regions in I, corrected for their position in the original input 
    &#34;&#34;&#34;
    
    ls = []
    xf = [image.shape[1], image.shape[2]]

    start = (0, 0)
    end = (xf[0], xf[1])

    size = (end[0] - start[0], end[1] - start[1])
    srs = [[(start, size)] for r in range(len(tolerance))]
    finished = [[] for r in range(len(tolerance))]

    k = 0

    while len(srs[0]) &gt; 0 and k &lt; max_depth:
        all_ = [[] for r in range(len(tolerance))]

        for sr in srs[0]:
            s = self.do_all_optim_tol(image, label, sr[0], sr[1], tolerance, debug)

            for r in range(len(tolerance)):
                if len(srs[r]) &gt; 0:
                    if s[r] == []:
                        coords = np.array([sr[0][0] + sx, sr[0][1] + sy])
                        finished[r].append((coords, sr[1]))
                    else:
                        all_[r] += s[r]

        for r in range(len(tolerance)):
            srs[r] = all_[r]

        k += 1

    for r in range(len(tolerance)):
        if len(srs[r]) == 0:
            ls.extend(finished[r])
        else:
            print(&#34;Max depth of %d reached at tolerance %.3f&#34; % (max_depth, tolerance[r]))

    return ls</code></pre>
</details>
</dd>
<dt id="Hierarchical Shapley.HierarchicalShapley.HierarchicalShap.get_salient_regions"><code class="name flex">
<span>def <span class="ident">get_salient_regions</span></span>(<span>self, shapley_values, tol, regions)</span>
</code></dt>
<dd>
<div class="desc"><p>Determine which of the 4 quadrants are salient, i.e. have Shapley value larger than tol.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>shapley_values</code></strong> :&ensp;<code>array</code> of <code>shape (2,2) </code></dt>
<dd>the shapley coefficients of each quadrant</dd>
<dt><strong><code>tol</code></strong> :&ensp;<code>float </code></dt>
<dd>the specified tolerance for a sub-region to be considered salient</dd>
<dt><strong><code>regions</code></strong> :&ensp;<code>the coordinates associated with each quadrant</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>srs</code></strong> :&ensp;<code>list</code> of <code>tuples</code> of <code>tuples</code> of <code>ints </code></dt>
<dd>a list of all salient regions (a tuple with start coordinates, size), i.e. regions whose Shapley values were large enough</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_salient_regions(self, shapley_values, tol, regions):
    &#34;&#34;&#34; Determine which of the 4 quadrants are salient, i.e. have Shapley value larger than tol.
    
    Parameters
    ----------
    shapley_values : array of shape (2,2) 
        the shapley coefficients of each quadrant
    tol : float 
        the specified tolerance for a sub-region to be considered salient
    regions : the coordinates associated with each quadrant
    
    Returns
    --------
    srs : list of tuples of tuples of ints 
        a list of all salient regions (a tuple with start coordinates, size), i.e. regions whose Shapley values were large enough
    &#34;&#34;&#34;
    
    srs = []
    for i in range(len(shapley_values)):
        for j in range(len(shapley_values[0])):
            if shapley_values[i, j] &gt; tol:
                srs.append(regions[i, j])

    return srs</code></pre>
</details>
</dd>
<dt id="Hierarchical Shapley.HierarchicalShapley.HierarchicalShap.get_salient_regions_optim_tol"><code class="name flex">
<span>def <span class="ident">get_salient_regions_optim_tol</span></span>(<span>self, shapley_values, tols, regions)</span>
</code></dt>
<dd>
<div class="desc"><p>Determine which of the 4 quadrants are salient, i.e. have Shapley value larger than tol.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>shapley_values</code></strong> :&ensp;<code>array</code> of <code>shape (2,2)</code></dt>
<dd>the Shapley coefficients associated with each quadrant</dd>
<dt><strong><code>tol</code></strong> :&ensp;<code>float</code></dt>
<dd>the specified tolerance for a sub-region to be considered salient</dd>
<dt><strong><code>regions</code></strong> :&ensp;<code>the coordinates associated with each quadrant</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>srs</code></strong> :&ensp;<code>list</code> of <code>tuples</code> of <code>tuples</code> of <code>ints </code></dt>
<dd>a list of all salient regions (a tuple with start coordinates, size), i.e. regions whose Shapley values were large enough</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_salient_regions_optim_tol(self, shapley_values, tols, regions):
    &#34;&#34;&#34; Determine which of the 4 quadrants are salient, i.e. have Shapley value larger than tol.
    
    Parameters
    ----------
    shapley_values : array of shape (2,2)
        the Shapley coefficients associated with each quadrant
    tol : float
        the specified tolerance for a sub-region to be considered salient
    regions : the coordinates associated with each quadrant
    
    Returns
    --------
    srs : list of tuples of tuples of ints 
        a list of all salient regions (a tuple with start coordinates, size), i.e. regions whose Shapley values were large enough
    &#34;&#34;&#34;
    
    srs = [[] for r in range(len(tols))]
    for i in range(len(shapley_values)):
        for j in range(len(shapley_values[0])):
            for r in range(len(tols)):
                if shapley_values[i, j] &gt; tols[r]:
                    srs[r].append(regions[i, j])
    return srs</code></pre>
</details>
</dd>
<dt id="Hierarchical Shapley.HierarchicalShapley.HierarchicalShap.saliency_map"><code class="name flex">
<span>def <span class="ident">saliency_map</span></span>(<span>self, image, label, tolerance, only_one_run=False, debug=False, max_depth=30, filename=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Create and then show a saliency map built with the Hierarchical Shapley method.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>image</code></strong> :&ensp;<code>torch tensor </code></dt>
<dd>the input image</dd>
<dt><strong><code>label</code></strong> :&ensp;<code>int in {0,1}</code></dt>
<dd>the label with respect to which we want to analyze - typically 1</dd>
<dt><strong><code>tolerance</code></strong> :&ensp;<code>float</code></dt>
<dd>the specified tolerance for a sub-region to be considered salient. A list is expected.</dd>
<dt><strong><code>only_one_run</code></strong> :&ensp;<code>bool</code></dt>
<dd>when False, several runs are done by also considering 16 cropped versions of the input</dd>
<dt><strong><code>debug</code></strong> :&ensp;<code>bool</code></dt>
<dd>if True, all subsets, there associated scores and the Shapley values will be displayed</dd>
<dt><strong><code>max_depth</code></strong> :&ensp;<code>int</code></dt>
<dd>the maximum number of divisions you want to allow before deciding the tolerance is too low.</dd>
<dt><strong><code>filename</code></strong> :&ensp;<code>string</code></dt>
<dd>name of the file to save the figure to</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>mask</code></strong> :&ensp;<code>numpy array</code></dt>
<dd>the saliency map</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def saliency_map(self, image, label, tolerance, only_one_run=False, debug=False, max_depth=30, filename=None):
    &#34;&#34;&#34; Create and then show a saliency map built with the Hierarchical Shapley method.
    
    Parameters
    ----------
    image : torch tensor 
        the input image
    label : int in {0,1}
        the label with respect to which we want to analyze - typically 1
    tolerance : float
        the specified tolerance for a sub-region to be considered salient. A list is expected.
    only_one_run : bool
        when False, several runs are done by also considering 16 cropped versions of the input
    debug : bool
        if True, all subsets, there associated scores and the Shapley values will be displayed
    max_depth : int
        the maximum number of divisions you want to allow before deciding the tolerance is too low.
    filename : string
        name of the file to save the figure to
    
    Returns
    -------
    mask : numpy array
        the saliency map 
    &#34;&#34;&#34;
    
    ls = []
    count = np.zeros(image.shape)
    xf = [image.shape[1], image.shape[2]]

    if only_one_run:
        starts = [(0, 0)]
        ends = [(xf[0], xf[1])]
    else:
        delta = [image.shape[1] // 20, image.shape[2] // 24]
        starts = [(0, 0), (0, delta[1]), (delta[0], 0), (delta[0], delta[1])]
        ends = [(xf[0], xf[1]), (xf[0], xf[1] - delta[1]), (xf[0] - delta[0], xf[1]),
                (xf[0] - delta[0], xf[1] - delta[1])]

    for start in starts:
        for end in ends:
            size = (end[0] - start[0], end[1] - start[1])
            count[:, start[0]:end[0], start[1]:end[1]] += np.ones((3, size[0], size[1]))

    for tol in tolerance:
        try:
            for start in starts:
                for end in ends:

                    size = (end[0] - start[0], end[1] - start[1])
                    srs = [(start, size)]
                    finished = []
                    k = 0

                    while len(srs) &gt; 0:

                        if k &gt; max_depth:
                            raise RuntimeError(&#34;Depth %d reached at tolerance %f&#34; % (k, tol))
                        all_ = []
                        for sr in srs:
                            s = self.do_all(image, label, sr[0], sr[1], tol, debug)
                            if s == []:
                                finished.append(((sr[0]), (sr[1])))

                            else:
                                all_ += s
                        srs = all_
                        k += 1
                    ls.append(finished)
        except RuntimeError as w:
            print(w, &#34;Run ignored, consider increasing tolerance.&#34;)

    mask = self.display_salient(image, ls, count, filename)
    return mask</code></pre>
</details>
</dd>
<dt id="Hierarchical Shapley.HierarchicalShapley.HierarchicalShap.saliency_map_optim_all"><code class="name flex">
<span>def <span class="ident">saliency_map_optim_all</span></span>(<span>self, image, label, tolerance, debug=False, max_depth=30, filename=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Create and then show a saliency map built with the Hierarchical Shapley method
(optimized for using several cropped version of the initial input and several tolerance thresholds).</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>im</code></strong> :&ensp;<code>torch tensor </code></dt>
<dd>the input image</dd>
<dt><strong><code>label</code></strong> :&ensp;<code>int in {0,1}</code></dt>
<dd>the label with respect to which we want to analyze - typically 1</dd>
<dt><strong><code>tolerance</code></strong> :&ensp;<code>float</code> or <code>list</code> of <code>floats</code></dt>
<dd>the specified tolerance for a sub-region to be considered salient. A list is expected.</dd>
<dt><strong><code>only_one_run</code></strong> :&ensp;<code>bool</code></dt>
<dd>when False, several runs are done by also considering 16 cropped versions of the input</dd>
<dt><strong><code>debug</code></strong> :&ensp;<code>bool</code></dt>
<dd>if True, all subsets, there associated scores and the Shapley values will be displayed</dd>
<dt><strong><code>max_depth</code></strong> :&ensp;<code>int</code></dt>
<dd>the maximum number of divisions you want to allow before deciding the tolerance is too low.</dd>
<dt><strong><code>filename</code></strong> :&ensp;<code>string </code></dt>
<dd>name of the file to save the figure to</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>mask</code></strong> :&ensp;<code>numpy array </code></dt>
<dd>the saliency map</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def saliency_map_optim_all(self, image, label, tolerance, debug=False, max_depth=30, filename=None):
    &#34;&#34;&#34; Create and then show a saliency map built with the Hierarchical Shapley method
    (optimized for using several cropped version of the initial input and several tolerance thresholds).
    
    Parameters
    ----------
    im : torch tensor 
        the input image
    label : int in {0,1}
        the label with respect to which we want to analyze - typically 1
    tolerance : float or list of floats
        the specified tolerance for a sub-region to be considered salient. A list is expected.
    only_one_run : bool
        when False, several runs are done by also considering 16 cropped versions of the input
    debug : bool
        if True, all subsets, there associated scores and the Shapley values will be displayed
    max_depth : int
        the maximum number of divisions you want to allow before deciding the tolerance is too low.
    filename : string 
        name of the file to save the figure to
    
    Returns
    -------
    mask : numpy array 
        the saliency map 
    &#34;&#34;&#34;
    
    ls = []

    xf = [image.shape[1], image.shape[2]]

    start = (0, 0)
    end = (xf[0], xf[1])
    size = (end[0] - start[0], end[1] - start[1])
    lx, ly = image.shape[1], image.shape[2]
    dx, dy = image.shape[1] // 4, image.shape[2] // 4

    # normal
    a = self.get_list_optim_tol(image, label, tolerance, 0, 0, debug=False, max_depth=30)
    ls.append(a)
    count = np.ones(image.shape)

    # shifted to bottom right
    image_br = self.background.clone()
    image_br[:, :lx - dx, :ly - dy] = image[:, dx:, dy:]
    a = self.get_list_optim_tol(image_br, label, tolerance, dx, dy, debug=False, max_depth=30)
    ls.append(a)
    count[:, dx:, dy:] += np.ones((3, lx - dx, ly - dy))

    # shifted to bottom left
    image_bl = self.background.clone()
    image_bl[:, :lx - dx, dy:] = image[:, dx:, :ly - dy]
    a = self.get_list_optim_tol(image_bl, label, tolerance, dx, -dy, debug=False, max_depth=30)
    ls.append(a)
    count[:, dx:, :ly - dy] += np.ones((3, lx - dx, ly - dy))

    # shifted to top left
    image_tl = self.background.clone()
    image_tl[:, dx:, dy:] = image[:, :lx - dx, :ly - dy]
    a = self.get_list_optim_tol(image_tl, label, tolerance, -dx, -dy, debug=False, max_depth=30)
    ls.append(a)
    count[:, :lx - dx, :ly - dy] += np.ones((3, lx - dx, ly - dy))

    # shifted to top right
    image_tr = self.background.clone()
    image_tr[:, dx:, :ly - dy] = image[:, :lx - dx, dy:]
    a = self.get_list_optim_tol(image_tr, label, tolerance, -dx, dy, debug=False, max_depth=30)
    ls.append(a)
    count[:, :lx - dx, dy:] += np.ones((3, lx - dx, ly - dy))
    
    mask = self.display_salient_optim_rand(image, ls, count, filename)
    return mask</code></pre>
</details>
</dd>
<dt id="Hierarchical Shapley.HierarchicalShapley.HierarchicalShap.saliency_map_optim_rand"><code class="name flex">
<span>def <span class="ident">saliency_map_optim_rand</span></span>(<span>self, image, label, tolerance, debug=False, max_depth=30, filename=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Create and then show a saliency map built with the Hierarchical Shapley method
(optimized for using several cropped versions of the original input). </p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>im</code></strong> :&ensp;<code>torch tensor </code></dt>
<dd>the input image</dd>
<dt><strong><code>label</code></strong> :&ensp;<code>int in {0,1}</code></dt>
<dd>the label with respect to which we want to analyze - typically 1</dd>
<dt><strong><code>tolerance</code></strong> :&ensp;<code>float</code> or <code>list</code> of <code>floats</code></dt>
<dd>the tolerance for a sub-region to be considered salient. A list is expected.</dd>
<dt><strong><code>only_one_run</code></strong> :&ensp;<code>bool </code></dt>
<dd>when False, several runs are done by also considering 16 cropped versions of the input</dd>
<dt><strong><code>debug</code></strong> :&ensp;<code>bool </code></dt>
<dd>if True, all subsets, there associated scores and the Shapley values will be displayed</dd>
<dt><strong><code>max_depth</code></strong> :&ensp;<code>int</code></dt>
<dd>the maximum number of divisions you want to allow before deciding the tolerance is too low.</dd>
<dt><strong><code>filename</code></strong> :&ensp;<code>string </code></dt>
<dd>name of the file to save the figure to</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>mask</code></strong> :&ensp;<code>numpy array</code></dt>
<dd>the saliency map</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def saliency_map_optim_rand(self, image, label, tolerance, debug=False, max_depth=30, filename=None):
    &#34;&#34;&#34; Create and then show a saliency map built with the Hierarchical Shapley method 
    (optimized for using several cropped versions of the original input). 
    
    Parameters
    ----------
    im : torch tensor 
        the input image
    label : int in {0,1}
        the label with respect to which we want to analyze - typically 1
    tolerance : float or list of floats
        the tolerance for a sub-region to be considered salient. A list is expected.
    only_one_run : bool 
        when False, several runs are done by also considering 16 cropped versions of the input
    debug : bool 
        if True, all subsets, there associated scores and the Shapley values will be displayed
    max_depth : int
        the maximum number of divisions you want to allow before deciding the tolerance is too low.
    filename : string 
        name of the file to save the figure to
        
    Returns
    -------
    mask : numpy array
        the saliency map 
    &#34;&#34;&#34;
    
    ls = []

    xf = [image.shape[1], image.shape[2]]

    start = (0, 0)
    end = (xf[0], xf[1])
    size = (end[0] - start[0], end[1] - start[1])
    lx, ly = image.shape[1], image.shape[2]
    dx, dy = image.shape[1] // 4, image.shape[2] // 4

    def salient_regions(I, sx, sy):
        &#34;&#34;&#34; Get salient regions of image I, knowing that it has been shifted by sx and sy from the original input. &#34;&#34;&#34;
        
        finished = []

        for tol in tolerance:
            k = 0
            srs = [(start, size)]
            current = []
            while len(srs) &gt; 0 and k &lt; max_depth:
                all_ = []
                for sr in srs:
                    s = self.do_all(I, label, sr[0], sr[1], tol, debug)
                    if s == []:
                        coords = np.array([sr[0][0] + sx, sr[0][1] + sy])
                        current.append((coords, sr[1]))
                    else:
                        all_ += s
                srs = all_
                k += 1
            if (k &lt; max_depth):
                finished += current
        return finished

    # normal
    a = salient_regions(image, 0, 0)
    ls.append(a)
    count = np.ones(image.shape)

    # shifted to bottom right
    image_br = self.background.clone()
    image_br[:, :lx - dx, :ly - dy] = image[:, dx:, dy:]
    ls.append(salient_regions(image_br, dx, dy))
    count[:, dx:, dy:] += np.ones((3, lx - dx, ly - dy))

    # shifted to bottom left
    image_bl = self.background.clone()
    image_bl[:, :lx - dx, dy:] = image[:, dx:, :ly - dy]
    ls.append(salient_regions(image_bl, dx, -dy))
    count[:, dx:, :ly - dy] += np.ones((3, lx - dx, ly - dy))

    # shifted to top left
    image_tl = self.background.clone()
    image_tl[:, dx:, dy:] = image[:, :lx - dx, :ly - dy]
    ls.append(salient_regions(image_tl, -dx, -dy))
    count[:, :lx - dx, :ly - dy] += np.ones((3, lx - dx, ly - dy))

    # shifted to top right
    image_tr = self.background.clone()
    image_tr[:, dx:, :ly - dy] = image[:, :lx - dx, dy:]
    ls.append(salient_regions(image_tr, -dx, dy))
    count[:, :lx - dx, dy:] += np.ones((3, lx - dx, ly - dy))

    mask = self.display_salient_optim_rand(image, ls, count, filename)
    return mask</code></pre>
</details>
</dd>
<dt id="Hierarchical Shapley.HierarchicalShapley.HierarchicalShap.saliency_map_optim_tol"><code class="name flex">
<span>def <span class="ident">saliency_map_optim_tol</span></span>(<span>self, image, label, tolerance, only_one_run=False, debug=False, max_depth=30, filename=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Create and then show a saliency map built with the Hierarchical Shapley method (optimized for when using a list of tolerances).</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>im</code></strong> :&ensp;<code>torch tensor </code></dt>
<dd>the input image</dd>
<dt><strong><code>label</code></strong> :&ensp;<code>int in {0,1}</code></dt>
<dd>the label with respect to which we want to analyze - typically 1</dd>
<dt><strong><code>tolerance</code></strong> :&ensp;<code>float</code> or <code>list</code> of <code>floats</code></dt>
<dd>the specified tolerance for a sub-region to be considered salient. A list is expected.</dd>
<dt><strong><code>only_one_run</code></strong> :&ensp;<code>bool </code></dt>
<dd>when False, several runs are done by also considering 16 cropped versions of the input</dd>
<dt><strong><code>debug</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>if True, all subsets, there associated scores and the Shapley values will be displayed</dd>
<dt><strong><code>max_depth</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>the maximum number of divisions you want to allow before deciding the tolerance is too low.</dd>
<dt><strong><code>filename</code></strong> :&ensp;<code>string</code>, optional</dt>
<dd>name of the file to save the figure to</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>mask</code></strong> :&ensp;<code>numpy array</code></dt>
<dd>the saliency map</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def saliency_map_optim_tol(self, image, label, tolerance, only_one_run=False, debug=False, max_depth=30,
                           filename=None):
    &#34;&#34;&#34; Create and then show a saliency map built with the Hierarchical Shapley method (optimized for when using a list of tolerances).
    
    Parameters
    ----------
    im : torch tensor 
        the input image
    label : int in {0,1}
        the label with respect to which we want to analyze - typically 1
    tolerance : float or list of floats
        the specified tolerance for a sub-region to be considered salient. A list is expected.
    only_one_run : bool 
        when False, several runs are done by also considering 16 cropped versions of the input
    debug : bool, optional 
        if True, all subsets, there associated scores and the Shapley values will be displayed
    max_depth : int, optional 
        the maximum number of divisions you want to allow before deciding the tolerance is too low.
    filename : string, optional 
        name of the file to save the figure to
    
    Returns
    -------
    mask : numpy array
        the saliency map 
    &#34;&#34;&#34;
    
    ls = []
    count = np.zeros(image.shape)
    xf = [image.shape[1], image.shape[2]]

    if only_one_run:
        starts = [(0, 0)]
        ends = [(xf[0], xf[1])]
    else:
        delta = [image.shape[1] // 20, image.shape[2] // 24]
        starts = [(0, 0), (0, delta[1]), (delta[0], 0), (delta[0], delta[1])]
        ends = [(xf[0], xf[1]), (xf[0], xf[1] - delta[1]), (xf[0] - delta[0], xf[1]),
                (xf[0] - delta[0], xf[1] - delta[1])]

    for start in starts:
        for end in ends:
            size = (end[0] - start[0], end[1] - start[1])
            count[:, start[0]:end[0], start[1]:end[1]] += np.ones((3, size[0], size[1]))

    for start in starts:
        for end in ends:

            size = (end[0] - start[0], end[1] - start[1])
            srs = [[(start, size)] for r in range(len(tolerance))]
            finished = [[] for r in range(len(tolerance))]
            was_finished = [True for r in range(len(tolerance))]
            k = 0

            while len(srs[0]) &gt; 0 and k &lt; max_depth:
                all_ = [[] for r in range(len(tolerance))]

                for sr in srs[0]:
                    s = self.do_all_optim_tol(image, label, sr[0], sr[1], tolerance, debug)

                    for r in range(len(tolerance)):
                        if len(srs[r]) &gt; 0:
                            if s[r] == []:
                                finished[r].append(((sr[0]), (sr[1])))
                            else:
                                all_[r] += s[r]

                for r in range(len(tolerance)):
                    srs[r] = all_[r]

                k += 1

            for r in range(len(tolerance)):
                if len(srs[r]) == 0:
                    ls.append(finished[r])
                else:
                    print(&#34;Max depth of %d reached at tolerance %.3f&#34; % (max_depth, tolerance[r]))

    mask = self.display_salient(image, ls, count, filename)
    return mask</code></pre>
</details>
</dd>
<dt id="Hierarchical Shapley.HierarchicalShapley.HierarchicalShap.shapley_of_quadrants"><code class="name flex">
<span>def <span class="ident">shapley_of_quadrants</span></span>(<span>self, score)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the Shapley values associated with each quadrant.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>score</code></strong> :&ensp;<code>the network evaluation for each subset</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>shapley_coefficients</code></strong> :&ensp;<code>array</code> of <code>shape (2,2) </code></dt>
<dd>the shapley coefficients of each quadrant</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def shapley_of_quadrants(self, score):
    &#34;&#34;&#34; Compute the Shapley values associated with each quadrant.
    
    Parameters
    ----------
    score : the network evaluation for each subset
    
    Returns
    --------
    shapley_coefficients : array of shape (2,2) 
        the shapley coefficients of each quadrant
    &#34;&#34;&#34;

    phi1 = (score[14] - score[15] + score[0] - score[1]) / 4\
           + (score[8] - score[11] + score[9] - score[12] + score[10] - score[13]
              + score[2] - score[5] + score[3] - score[6] + score[4] - score[7]) / 12

    phi2 = (score[13] - score[15] + score[0] - score[2]) / 4 \
           + (score[6] - score[11] + score[7] - score[12] + score[10] - score[14]
              + score[1] - score[5] + score[3] - score[8] + score[4] - score[9]) / 12

    phi3 = (score[12] - score[15] + score[0] - score[3]) / 4 \
           + (score[5] - score[11] + score[9] - score[14] + score[7] - score[13]
              + score[2] - score[8] + score[1] - score[6] + score[4] - score[10]) / 12

    phi4 = (score[11] - score[15] + score[0] - score[4]) / 4 \
           + (score[8] - score[14] + score[5] - score[12] + score[6] - score[13]
              + score[1] - score[7] + score[3] - score[10] + score[2] - score[9]) / 12

    shapley_coefficients = np.array([[phi1, phi2], [phi3, phi4]])
    
    return shapley_coefficients</code></pre>
</details>
</dd>
<dt id="Hierarchical Shapley.HierarchicalShapley.HierarchicalShap.subset_scores"><code class="name flex">
<span>def <span class="ident">subset_scores</span></span>(<span>self, sub, label)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the scores of each subset input.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>sub</code></strong> :&ensp;<code>the subsets</code> of <code>inputs</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>label : the class label - typically 1 -
in which we're interested.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>score</code></strong> :&ensp;<code>numpy array</code> of <code>shape (16,)</code></dt>
<dd>the scores for each input</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def subset_scores(self, sub, label):
    &#34;&#34;&#34; Compute the scores of each subset input.
    
    Parameters
    ----------
    sub : the subsets of inputs
    label : the class label - typically 1 -  in which we&#39;re interested.
    
    Returns
    --------
    score : numpy array of shape (16,)
        the scores for each input
    &#34;&#34;&#34;
    
    outputs = self.model(sub)
    score = outputs[:, label].detach().numpy()

    return score</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="Hierarchical Shapley" href="index.html">Hierarchical Shapley</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="Hierarchical Shapley.HierarchicalShapley.HierarchicalShap" href="#Hierarchical Shapley.HierarchicalShapley.HierarchicalShap">HierarchicalShap</a></code></h4>
<ul class="">
<li><code><a title="Hierarchical Shapley.HierarchicalShapley.HierarchicalShap.construct_subsets" href="#Hierarchical Shapley.HierarchicalShapley.HierarchicalShap.construct_subsets">construct_subsets</a></code></li>
<li><code><a title="Hierarchical Shapley.HierarchicalShapley.HierarchicalShap.display_cropped_images" href="#Hierarchical Shapley.HierarchicalShapley.HierarchicalShap.display_cropped_images">display_cropped_images</a></code></li>
<li><code><a title="Hierarchical Shapley.HierarchicalShapley.HierarchicalShap.display_salient" href="#Hierarchical Shapley.HierarchicalShapley.HierarchicalShap.display_salient">display_salient</a></code></li>
<li><code><a title="Hierarchical Shapley.HierarchicalShapley.HierarchicalShap.display_salient_optim_rand" href="#Hierarchical Shapley.HierarchicalShapley.HierarchicalShap.display_salient_optim_rand">display_salient_optim_rand</a></code></li>
<li><code><a title="Hierarchical Shapley.HierarchicalShapley.HierarchicalShap.do_all" href="#Hierarchical Shapley.HierarchicalShapley.HierarchicalShap.do_all">do_all</a></code></li>
<li><code><a title="Hierarchical Shapley.HierarchicalShapley.HierarchicalShap.do_all_optim_tol" href="#Hierarchical Shapley.HierarchicalShapley.HierarchicalShap.do_all_optim_tol">do_all_optim_tol</a></code></li>
<li><code><a title="Hierarchical Shapley.HierarchicalShapley.HierarchicalShap.get_list_optim_tol" href="#Hierarchical Shapley.HierarchicalShapley.HierarchicalShap.get_list_optim_tol">get_list_optim_tol</a></code></li>
<li><code><a title="Hierarchical Shapley.HierarchicalShapley.HierarchicalShap.get_salient_regions" href="#Hierarchical Shapley.HierarchicalShapley.HierarchicalShap.get_salient_regions">get_salient_regions</a></code></li>
<li><code><a title="Hierarchical Shapley.HierarchicalShapley.HierarchicalShap.get_salient_regions_optim_tol" href="#Hierarchical Shapley.HierarchicalShapley.HierarchicalShap.get_salient_regions_optim_tol">get_salient_regions_optim_tol</a></code></li>
<li><code><a title="Hierarchical Shapley.HierarchicalShapley.HierarchicalShap.saliency_map" href="#Hierarchical Shapley.HierarchicalShapley.HierarchicalShap.saliency_map">saliency_map</a></code></li>
<li><code><a title="Hierarchical Shapley.HierarchicalShapley.HierarchicalShap.saliency_map_optim_all" href="#Hierarchical Shapley.HierarchicalShapley.HierarchicalShap.saliency_map_optim_all">saliency_map_optim_all</a></code></li>
<li><code><a title="Hierarchical Shapley.HierarchicalShapley.HierarchicalShap.saliency_map_optim_rand" href="#Hierarchical Shapley.HierarchicalShapley.HierarchicalShap.saliency_map_optim_rand">saliency_map_optim_rand</a></code></li>
<li><code><a title="Hierarchical Shapley.HierarchicalShapley.HierarchicalShap.saliency_map_optim_tol" href="#Hierarchical Shapley.HierarchicalShapley.HierarchicalShap.saliency_map_optim_tol">saliency_map_optim_tol</a></code></li>
<li><code><a title="Hierarchical Shapley.HierarchicalShapley.HierarchicalShap.shapley_of_quadrants" href="#Hierarchical Shapley.HierarchicalShapley.HierarchicalShap.shapley_of_quadrants">shapley_of_quadrants</a></code></li>
<li><code><a title="Hierarchical Shapley.HierarchicalShapley.HierarchicalShap.subset_scores" href="#Hierarchical Shapley.HierarchicalShapley.HierarchicalShap.subset_scores">subset_scores</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.8.3</a>.</p>
</footer>
</body>
</html>