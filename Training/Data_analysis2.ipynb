{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data_analysis2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3-final"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lustea0201/Interpretability/blob/master/Training/Data_analysis2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uv-An0P9QTD",
        "colab_type": "text"
      },
      "source": [
        "# Importing the second dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h4NeSToBbJMn",
        "outputId": "1920d577-6462-4b98-de71-47c99c54d791",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "source": [
        "#@title\n",
        "import zipfile\n",
        "import io\n",
        "import cv2\n",
        "import glob \n",
        "import numpy as np\n",
        "import random \n",
        "import torch \n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor, Normalize\n",
        "from torchvision import transforms\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from google.colab import drive\n",
        "\n",
        "torch.manual_seed(0) # Reproducible, for now \n",
        "\n",
        "FIGSIZE = (12,10)\n",
        "\n",
        "!rm -rf main_dir\n",
        "!rm -rf data.zip\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "data = zipfile.ZipFile(\"/content/drive/My Drive/Interpretability/5000/data2/data.zip\", 'r')\n",
        "\n",
        "root_dir = \"main_dir\"\n",
        "data.extractall(root_dir)\n",
        "data.close()\n",
        "\n",
        "import sys\n",
        "sys.path.append('local_modules')\n",
        "\n",
        "!wget https://raw.githubusercontent.com/lustea0201/Interpretability/master/Utils/utils.py -P local_modules -nc\n",
        "import local_modules.utils as utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vAf1Fk2IbguJ",
        "colab": {}
      },
      "source": [
        "MEAN, STD = np.array([0.5, 0.5, 0.5]), np.array([0.5, 0.5, 0.5])\n",
        "\n",
        "transf = transforms.Compose( [ToTensor(), Normalize(mean=MEAN, std=STD)])\n",
        "train_data = ImageFolder(root = os.path.join(root_dir, 'train'), transform = transf)\n",
        "val_data = ImageFolder(root = os.path.join(root_dir, 'val'), transform = transf)\n",
        "test_data = ImageFolder(root = os.path.join(root_dir, 'test'), transform = transf)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZbOwxII9bcn",
        "colab_type": "text"
      },
      "source": [
        "# Dataset description \n",
        "\n",
        "\n",
        "*   Label 0: the image doesn't contain any shape \n",
        "*   Label 1: the image contains at least one shape \n",
        "\n",
        "Here are two examples: \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cSTJr4lCmYaB",
        "outputId": "7b2a98f8-1b99-48f6-b60f-fdee556bd17f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        }
      },
      "source": [
        "img0 = utils.input2image(train_data[0][0], MEAN, STD)\n",
        "img1 = utils.input2image(train_data[-1][0], MEAN, STD)\n",
        "utils.display_image(img0, train_data[0][1])      \n",
        "utils.display_image(img1, train_data[-1][1])     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hoo3HmSLqBbd",
        "colab": {}
      },
      "source": [
        "batch_Size = 64\n",
        "dataloader = DataLoader(train_data, batch_size = batch_Size, shuffle = True, num_workers = 0)\n",
        "valloader = DataLoader(val_data, batch_size = batch_Size, shuffle = True, num_workers = 0)\n",
        "testloader = DataLoader(test_data, batch_size = batch_Size, shuffle = True, num_workers = 0)\n",
        "train_loader = iter(dataloader)\n",
        "x,y = next(train_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkyIUp28HrrJ",
        "colab_type": "text"
      },
      "source": [
        "# Model description\n",
        "The neural network used to classify the images receives batches of 3x100x120 images. \n",
        "It consists of \n",
        "* two convolutional layers followed by max pooling \n",
        "* three fully connected layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7ZHuALqxGmy9",
        "outputId": "dacc2cb5-828b-4c7b-c864-a00a3784cca5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        }
      },
      "source": [
        "net = utils.Net()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters()) \n",
        "max_epochs = 50\n",
        "train_loss, val_loss, train_accuracy, val_accuracy = utils.train(net, optimizer, criterion, max_epochs, dataloader, valloader)\n",
        "utils.plot_training(train_loss, val_loss, train_accuracy, val_accuracy)\n",
        "wi, wl, wpl = utils.test(net, testloader)\n",
        "index = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_2qbFlsY0EY3",
        "outputId": "e927df6c-159a-4ce4-a764-4ee5225a9ec0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "if index in range(len(wi)):\n",
        "  I = utils.input2image(wi[index], MEAN, STD)\n",
        "  utils.display_image(I, wl[index], wpl[index])\n",
        "  outputs = net(wi[index].unsqueeze(0)).data\n",
        "  print(\"Score for predicted label: \", outputs.numpy()[0][wpl[index]])\n",
        "  print(\"Score for true label: \", outputs.numpy()[0][wl[index]])\n",
        "  index += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1u0zjyeN2AYr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rg1Ma1XyaSLM",
        "colab_type": "code",
        "outputId": "a857c3d7-5eac-4258-a451-fd2f593e1173",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "tags": []
      },
      "source": [
        "save = input(\"Overwrite current state dictionnary ? [y/n]\")\n",
        "if (save == 'y'): \n",
        "  torch.save(net.state_dict(), 'drive/My Drive/Interpretability/model2.pth')\n",
        "  print(\"State dictionnary saved.\")\n",
        "else: \n",
        "  print(\"State dictionnary has not been saved.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}